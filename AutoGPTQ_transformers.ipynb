{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dea435-da8b-42b6-8db1-08e9286ebf0e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-25T02:37:28.886221Z",
     "iopub.status.busy": "2024-01-25T02:37:28.885603Z",
     "iopub.status.idle": "2024-01-25T02:37:31.099607Z",
     "shell.execute_reply": "2024-01-25T02:37:31.098896Z",
     "shell.execute_reply.started": "2024-01-25T02:37:28.886190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig\n",
    "import torch\n",
    "\n",
    "#model_id='/mnt/workspace/opt-6.7b'\n",
    "model_id = \"/mnt/workspace/opt-2.7b\"\n",
    "\n",
    "quantization_config = GPTQConfig(\n",
    "     bits=4, # 量化精度\n",
    "     group_size=128,\n",
    "     dataset=\"wikitext2\",\n",
    "     #dataset=\"c4\",\n",
    "     desc_act=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03890b4-7415-4fbf-8cf1-0c403327ab68",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-25T02:37:31.970495Z",
     "iopub.status.busy": "2024-01-25T02:37:31.969665Z",
     "iopub.status.idle": "2024-01-25T02:55:57.552267Z",
     "shell.execute_reply": "2024-01-25T02:55:57.551464Z",
     "shell.execute_reply.started": "2024-01-25T02:37:31.970464Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 10:37:34.031626: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Wed Jan 24 17:33:16 2024).\n",
      "Quantizing model.decoder.layers blocks :   0%|          | 0/32 [00:00<?, ?it/s]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:04<00:24,  4.88s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:07<00:14,  3.56s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:10<00:09,  3.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:12<00:05,  2.93s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:15<00:02,  2.83s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:25<00:00,  5.29s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   3%|▎         | 1/32 [00:26<13:48, 26.72s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   6%|▋         | 2/32 [00:51<12:42, 25.41s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   9%|▉         | 3/32 [01:15<12:05, 25.02s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.18s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  12%|█▎        | 4/32 [01:40<11:35, 24.82s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.63s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  16%|█▌        | 5/32 [02:04<11:07, 24.70s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.19s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  19%|█▉        | 6/32 [02:29<10:42, 24.69s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.16s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  22%|██▏       | 7/32 [02:53<10:15, 24.64s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.19s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  25%|██▌       | 8/32 [03:18<09:50, 24.62s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  28%|██▊       | 9/32 [03:43<09:25, 24.59s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  31%|███▏      | 10/32 [04:07<09:01, 24.61s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  34%|███▍      | 11/32 [04:32<08:37, 24.64s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.21s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  38%|███▊      | 12/32 [04:57<08:12, 24.65s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:08,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.18s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  41%|████      | 13/32 [05:21<07:48, 24.63s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.18s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  44%|████▍     | 14/32 [05:46<07:23, 24.62s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.19s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  47%|████▋     | 15/32 [06:10<06:58, 24.61s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  50%|█████     | 16/32 [06:35<06:33, 24.58s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.22s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  53%|█████▎    | 17/32 [07:00<06:09, 24.62s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.17s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  56%|█████▋    | 18/32 [07:24<05:44, 24.61s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.26s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  59%|█████▉    | 19/32 [07:49<05:20, 24.68s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.70s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  62%|██████▎   | 20/32 [08:14<04:56, 24.70s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  66%|██████▌   | 21/32 [08:38<04:31, 24.69s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.18s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  69%|██████▉   | 22/32 [09:03<04:06, 24.66s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.74s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.21s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  72%|███████▏  | 23/32 [09:28<03:42, 24.67s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.18s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  75%|███████▌  | 24/32 [09:52<03:17, 24.64s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.72s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.19s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  78%|███████▊  | 25/32 [10:17<02:52, 24.64s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.19s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  81%|████████▏ | 26/32 [10:42<02:27, 24.63s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.23s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  84%|████████▍ | 27/32 [11:06<02:03, 24.65s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:08<00:08,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  88%|████████▊ | 28/32 [11:31<01:38, 24.66s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.69s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.22s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  91%|█████████ | 29/32 [11:56<01:14, 24.69s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.23s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  94%|█████████▍| 30/32 [12:20<00:49, 24.70s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.21s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  97%|█████████▋| 31/32 [12:45<00:24, 24.70s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:23<00:00,  5.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks : 100%|██████████| 32/32 [13:10<00:00, 24.70s/it]\n",
      "Using Exllamav2 backend will reorder the weights offline, thus you will not be able to save the model with the right weights.Setting `disable_exllama=True`. You should only use Exllamav2 backend for inference. \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id,local_files_only=True)\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4200d290-5ba5-4f77-916e-727021c30327",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-25T04:25:23.613373Z",
     "iopub.status.busy": "2024-01-25T04:25:23.612734Z",
     "iopub.status.idle": "2024-01-25T04:25:24.325479Z",
     "shell.execute_reply": "2024-01-25T04:25:24.324648Z",
     "shell.execute_reply.started": "2024-01-25T04:25:23.613344Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Thu Jan 25 12:25:24 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |   9482MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a6d8bf-d940-435c-8a64-b540f705a992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T04:26:07.000693Z",
     "iopub.status.busy": "2024-01-25T04:26:07.000119Z",
     "iopub.status.idle": "2024-01-25T04:26:07.022486Z",
     "shell.execute_reply": "2024-01-25T04:26:07.021787Z",
     "shell.execute_reply.started": "2024-01-25T04:26:07.000657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict([('qweight',\n",
       "               tensor([[ 1766754698, -1249142373,  1183631034,  ..., -2038658921,\n",
       "                        -2037544795, -1956877206],\n",
       "                       [ 1772710025,  1739893370, -1500087466,  ...,  2021033895,\n",
       "                         -662329995,  1756019066],\n",
       "                       [ -895658394, -2007414633, -1951893913,  ..., -1429760649,\n",
       "                         -979785307,  1451914633],\n",
       "                       ...,\n",
       "                       [ 2025363833, -1412789579,  1539086474,  ...,   -57959783,\n",
       "                        -1737062521,  2092479849],\n",
       "                       [ 1753843080, -1432974698, -1788312443,  ..., -1431213944,\n",
       "                         2042127721,  1449641373],\n",
       "                       [ 1769506709, -2021287558, -1182099061,  ...,  1999993702,\n",
       "                         1754823336, -2072558201]], device='cuda:0', dtype=torch.int32)),\n",
       "              ('qzeros',\n",
       "               tensor([[2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       ...,\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071]], device='cuda:0', dtype=torch.int32)),\n",
       "              ('scales',\n",
       "               tensor([[0.0046, 0.0046, 0.0046,  ..., 0.0078, 0.0068, 0.0056],\n",
       "                       [0.0053, 0.0041, 0.0071,  ..., 0.0097, 0.0085, 0.0078],\n",
       "                       [0.0083, 0.0074, 0.0055,  ..., 0.0076, 0.0072, 0.0090],\n",
       "                       ...,\n",
       "                       [0.0050, 0.0056, 0.0055,  ..., 0.0061, 0.0074, 0.0091],\n",
       "                       [0.0041, 0.0046, 0.0047,  ..., 0.0080, 0.0096, 0.0062],\n",
       "                       [0.0093, 0.0063, 0.0062,  ..., 0.0061, 0.0067, 0.0056]],\n",
       "                      device='cuda:0', dtype=torch.float16)),\n",
       "              ('g_idx',\n",
       "               tensor([ 0,  0,  0,  ..., 19, 19, 19], device='cuda:0', dtype=torch.int32)),\n",
       "              ('bias',\n",
       "               tensor([-0.1272,  0.0172,  0.0103,  ..., -0.0928,  0.0567,  0.0510],\n",
       "                      device='cuda:0', dtype=torch.float16))]),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'infeatures': 2560,\n",
       " 'outfeatures': 2560,\n",
       " 'bits': 4,\n",
       " 'group_size': 128,\n",
       " 'maxq': 15,\n",
       " 'half_indim': 1280,\n",
       " 'use_cuda_fp16': True,\n",
       " 'wf': tensor([[ 0,  4,  8, 12, 16, 20, 24, 28]], dtype=torch.int32),\n",
       " 'kernel_switch_threshold': 128,\n",
       " 'autogptq_cuda_available': False,\n",
       " 'autogptq_cuda': None,\n",
       " 'trainable': False,\n",
       " 'device': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model.model.decoder.layers[0].self_attn.q_proj.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41536c4-031b-49aa-9147-eea6c94f0d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T04:29:04.233226Z",
     "iopub.status.busy": "2024-01-25T04:29:04.232550Z",
     "iopub.status.idle": "2024-01-25T04:29:07.489446Z",
     "shell.execute_reply": "2024-01-25T04:29:07.488822Z",
     "shell.execute_reply.started": "2024-01-25T04:29:04.233193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas! I'm glad to see you're still here.\n",
      "Thank you! I'm glad to be here too.\n"
     ]
    }
   ],
   "source": [
    "text = \"Merry Christmas! I'm glad to\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = quant_model.generate(**inputs, max_new_tokens=64)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00c2422-a8d1-48fb-89ce-5ff72ce6410a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-25T04:31:16.369531Z",
     "iopub.status.busy": "2024-01-25T04:31:16.368625Z",
     "iopub.status.idle": "2024-01-25T04:39:49.529787Z",
     "shell.execute_reply": "2024-01-25T04:39:49.528784Z",
     "shell.execute_reply.started": "2024-01-25T04:31:16.369493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantizing model.decoder.layers blocks :   0%|          | 0/32 [00:00<?, ?it/s]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   3%|▎         | 1/32 [00:10<05:37, 10.89s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   6%|▋         | 2/32 [00:21<05:27, 10.90s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   9%|▉         | 3/32 [00:32<05:15, 10.86s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.44s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  12%|█▎        | 4/32 [00:43<05:02, 10.81s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  16%|█▌        | 5/32 [00:54<04:53, 10.86s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:06,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  19%|█▉        | 6/32 [01:05<04:42, 10.88s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  22%|██▏       | 7/32 [01:16<04:32, 10.90s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:06,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  25%|██▌       | 8/32 [01:27<04:21, 10.90s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:06,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  28%|██▊       | 9/32 [01:38<04:11, 10.91s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  31%|███▏      | 10/32 [01:48<04:00, 10.94s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.50s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  34%|███▍      | 11/32 [01:59<03:49, 10.94s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.50s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  38%|███▊      | 12/32 [02:10<03:38, 10.95s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  41%|████      | 13/32 [02:21<03:27, 10.93s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.51s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  44%|████▍     | 14/32 [02:32<03:17, 10.95s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  47%|████▋     | 15/32 [02:43<03:06, 10.96s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  50%|█████     | 16/32 [02:54<02:55, 10.96s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  53%|█████▎    | 17/32 [03:05<02:44, 10.97s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  56%|█████▋    | 18/32 [03:16<02:33, 10.98s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  59%|█████▉    | 19/32 [03:27<02:22, 10.98s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  62%|██████▎   | 20/32 [03:38<02:11, 10.94s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  66%|██████▌   | 21/32 [03:49<02:00, 10.93s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.51s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  69%|██████▉   | 22/32 [04:00<01:49, 10.97s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.51s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  72%|███████▏  | 23/32 [04:11<01:38, 10.99s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.22s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.51s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  75%|███████▌  | 24/32 [04:22<01:28, 11.01s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.50s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  78%|███████▊  | 25/32 [04:33<01:17, 11.01s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  81%|████████▏ | 26/32 [04:44<01:06, 11.01s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:11<00:00,  2.51s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  84%|████████▍ | 27/32 [04:55<00:55, 11.03s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  88%|████████▊ | 28/32 [05:06<00:43, 10.98s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:06,  1.21s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  91%|█████████ | 29/32 [05:17<00:32, 10.97s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  94%|█████████▍| 30/32 [05:28<00:21, 10.96s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  97%|█████████▋| 31/32 [05:39<00:10, 10.91s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.50s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks : 100%|██████████| 32/32 [05:50<00:00, 10.94s/it]\n",
      "Using Exllamav2 backend will reorder the weights offline, thus you will not be able to save the model with the right weights.Setting `disable_exllama=True`. You should only use Exllamav2 backend for inference. \n"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "from transformers import AutoModelForCausalLM, GPTQConfig, AutoTokenizer\n",
    "\n",
    "model_id = \"/mnt/workspace/opt-2.7b\"\n",
    "\n",
    "quantization_config = GPTQConfig(\n",
    "    bits=4,\n",
    "    group_size=128,\n",
    "    desc_act=False,\n",
    "    dataset=[\"auto-gptq is an easy-to-use model quantization library with user-friendly apis, based on GPTQ algorithm.\"]\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecc6753-2d48-4f60-bbc2-7d9e0f7238dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T04:39:49.539262Z",
     "iopub.status.busy": "2024-01-25T04:39:49.538992Z",
     "iopub.status.idle": "2024-01-25T04:39:50.003280Z",
     "shell.execute_reply": "2024-01-25T04:39:50.002609Z",
     "shell.execute_reply.started": "2024-01-25T04:39:49.539232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas! I'm glad to.\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text = \"Merry Christmas! I'm glad to\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = quant_model.generate(**inputs, max_new_tokens=64)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f474ef65-0210-44b7-b199-b4ecb69d0d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transf",
   "language": "python",
   "name": "transf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

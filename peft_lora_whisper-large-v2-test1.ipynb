{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f0574-ab60-44a6-9fb5-d9fd9b1e9c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T06:00:12.129982Z",
     "iopub.status.busy": "2024-01-29T06:00:12.129585Z",
     "iopub.status.idle": "2024-01-29T06:00:12.135894Z",
     "shell.execute_reply": "2024-01-29T06:00:12.135331Z",
     "shell.execute_reply.started": "2024-01-29T06:00:12.129954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805f5713-bb64-4f53-a8cb-a57558c42b1d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T16:23:06.033171Z",
     "iopub.status.busy": "2024-01-31T16:23:06.032310Z",
     "iopub.status.idle": "2024-01-31T16:23:06.037340Z",
     "shell.execute_reply": "2024-01-31T16:23:06.036439Z",
     "shell.execute_reply.started": "2024-01-31T16:23:06.033133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"/mnt/data/whisper-large-v2\"\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "task = \"transcribe\"\n",
    "#dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae99d94e-d759-43f8-b9aa-0d50cd3dd1be",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T16:23:08.342297Z",
     "iopub.status.busy": "2024-01-31T16:23:08.341868Z",
     "iopub.status.idle": "2024-01-31T16:27:57.018968Z",
     "shell.execute_reply": "2024-01-31T16:27:57.018369Z",
     "shell.execute_reply.started": "2024-01-31T16:23:08.342272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10581/10581 [01:15<00:00, 140.50it/s]\n",
      "100%|██████████| 29056/29056 [03:30<00:00, 137.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_common_voice_11_0_dataset(audiofolder, metafile, split):\n",
    "    dataset = load_dataset(\"audiofolder\", data_dir=audiofolder, split=split)\n",
    "    meta = pd.read_table(metafile)\n",
    "    new_column = []\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        new_column.append(meta[meta[\"path\"] == dataset[i][\"audio\"][\"path\"].split(\"/\")[-1]][\"sentence\"].values[0])\n",
    "    dataset = dataset.add_column(\"sentence\", new_column)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"test\"] = load_common_voice_11_0_dataset(\"/mnt/workspace/common_voice_11_0/audio/zh-CN/test\", \"/mnt/workspace/common_voice_11_0/transcript/zh-CN/test.tsv\", \"test\")\n",
    "common_voice[\"train\"] = load_common_voice_11_0_dataset(\"/mnt/workspace/common_voice_11_0/audio/zh-CN/train\", \"/mnt/workspace/common_voice_11_0/transcript/zh-CN/train.tsv\", \"train\")\n",
    "\n",
    "#common_voice[\"train\"] = load_dataset(dataset_name, language_abbr, split=\"train+validation\")\n",
    "#common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ed081c-44df-4ced-96ea-f73c4d47c7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:22:40.733970Z",
     "iopub.status.busy": "2024-01-31T10:22:40.733535Z",
     "iopub.status.idle": "2024-01-31T10:22:40.749755Z",
     "shell.execute_reply": "2024-01-31T10:22:40.749208Z",
     "shell.execute_reply.started": "2024-01-31T10:22:40.733940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/616afb8263d97d1bc72ed4c5cfd3814f88761dc484aac6018582fec4883786e2/zh-CN_train_0/common_voice_zh-CN_18531536.mp3',\n",
       "  'array': array([ 0.00000000e+00,  9.86623760e-13,  1.28757139e-15, ...,\n",
       "          2.35939888e-06, -9.32492367e-06, -6.35876040e-06]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': '汉元鼎六年，武帝平定南越国，南越之地重新划郡，番禺仍为南海郡治。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569f463d-2017-41b5-a982-bb128b567de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:30:57.341419Z",
     "iopub.status.busy": "2024-01-31T16:30:57.340974Z",
     "iopub.status.idle": "2024-01-31T16:30:59.347826Z",
     "shell.execute_reply": "2024-01-31T16:30:59.347154Z",
     "shell.execute_reply.started": "2024-01-31T16:30:57.341390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoTokenizer, AutoProcessor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, language=language, task=task)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name_or_path, language=language, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f614c77f-f488-4e95-b3fa-9af7a6f88cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:22:52.805872Z",
     "iopub.status.busy": "2024-01-31T10:22:52.805101Z",
     "iopub.status.idle": "2024-01-31T10:22:52.810178Z",
     "shell.execute_reply": "2024-01-31T10:22:52.809541Z",
     "shell.execute_reply.started": "2024-01-31T10:22:52.805834Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/whisper-large-v2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d7621c-38c4-4840-b780-4b89776b3703",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T10:22:55.479717Z",
     "iopub.status.busy": "2024-01-31T10:22:55.479113Z",
     "iopub.status.idle": "2024-01-31T10:22:55.493218Z",
     "shell.execute_reply": "2024-01-31T10:22:55.492688Z",
     "shell.execute_reply.started": "2024-01-31T10:22:55.479688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/616afb8263d97d1bc72ed4c5cfd3814f88761dc484aac6018582fec4883786e2/zh-CN_train_0/common_voice_zh-CN_18531536.mp3',\n",
       "  'array': array([ 0.00000000e+00,  9.86623760e-13,  1.28757139e-15, ...,\n",
       "          2.35939888e-06, -9.32492367e-06, -6.35876040e-06]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': '汉元鼎六年，武帝平定南越国，南越之地重新划郡，番禺仍为南海郡治。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#common_voice = common_voice.remove_columns(\n",
    "#    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
    "#)\n",
    "common_voice[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e61a93-8bcf-4656-a9b1-88bc3ccd6e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:22:57.873057Z",
     "iopub.status.busy": "2024-01-31T10:22:57.872581Z",
     "iopub.status.idle": "2024-01-31T10:22:57.877640Z",
     "shell.execute_reply": "2024-01-31T10:22:57.876971Z",
     "shell.execute_reply.started": "2024-01-31T10:22:57.873031Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': ['audio', 'sentence'], 'train': ['audio', 'sentence']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a2a5a3-9884-4cea-9782-4dc5694b5bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:31:06.124189Z",
     "iopub.status.busy": "2024-01-31T16:31:06.123414Z",
     "iopub.status.idle": "2024-01-31T16:31:06.132782Z",
     "shell.execute_reply": "2024-01-31T16:31:06.132201Z",
     "shell.execute_reply.started": "2024-01-31T16:31:06.124162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de76f26-f62c-4d92-8367-29ce282b8f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:22:59.580767Z",
     "iopub.status.busy": "2024-01-31T10:22:59.580346Z",
     "iopub.status.idle": "2024-01-31T10:22:59.598476Z",
     "shell.execute_reply": "2024-01-31T10:22:59.597953Z",
     "shell.execute_reply.started": "2024-01-31T10:22:59.580742Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/616afb8263d97d1bc72ed4c5cfd3814f88761dc484aac6018582fec4883786e2/zh-CN_train_0/common_voice_zh-CN_18531536.mp3',\n",
       "  'array': array([-1.23691279e-10, -1.16415322e-10, -5.45696821e-11, ...,\n",
       "         -7.22276309e-06, -1.77195689e-05, -8.53491656e-07]),\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': '汉元鼎六年，武帝平定南越国，南越之地重新划郡，番禺仍为南海郡治。'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f1c244-2de7-4e6f-b4e7-38a45fcd1303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:31:11.833643Z",
     "iopub.status.busy": "2024-01-31T16:31:11.833042Z",
     "iopub.status.idle": "2024-01-31T16:31:11.837465Z",
     "shell.execute_reply": "2024-01-31T16:31:11.836753Z",
     "shell.execute_reply.started": "2024-01-31T16:31:11.833616Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5ad1f6-2d12-4ec7-b534-43496c3e7eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:31:15.268693Z",
     "iopub.status.busy": "2024-01-31T16:31:15.267913Z",
     "iopub.status.idle": "2024-01-31T16:31:15.363686Z",
     "shell.execute_reply": "2024-01-31T16:31:15.363071Z",
     "shell.execute_reply.started": "2024-01-31T16:31:15.268657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e58c12-6dad-4088-847e-4a794b0d2968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:31:33.491885Z",
     "iopub.status.busy": "2024-01-31T16:31:33.491128Z",
     "iopub.status.idle": "2024-01-31T16:31:33.498427Z",
     "shell.execute_reply": "2024-01-31T16:31:33.497781Z",
     "shell.execute_reply.started": "2024-01-31T16:31:33.491856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06bcff98-a8e1-4bf9-a62e-40a33a290391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T00:29:50.096500Z",
     "iopub.status.busy": "2024-01-31T00:29:50.095918Z",
     "iopub.status.idle": "2024-01-31T00:29:50.099395Z",
     "shell.execute_reply": "2024-01-31T00:29:50.098744Z",
     "shell.execute_reply.started": "2024-01-31T00:29:50.096474Z"
    }
   },
   "outputs": [],
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b81fe8-4bee-4cc7-8f76-8f3422c2e4bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:32:40.927767Z",
     "iopub.status.busy": "2024-01-31T16:32:40.927344Z",
     "iopub.status.idle": "2024-01-31T16:33:17.000295Z",
     "shell.execute_reply": "2024-01-31T16:33:16.999653Z",
     "shell.execute_reply.started": "2024-01-31T16:32:40.927742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSpeechSeq2Seq\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b68a26b-aa51-4e11-b997-25b6b9d9e0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:24.029715Z",
     "iopub.status.busy": "2024-01-31T10:23:24.029302Z",
     "iopub.status.idle": "2024-01-31T10:23:24.033021Z",
     "shell.execute_reply": "2024-01-31T10:23:24.032455Z",
     "shell.execute_reply.started": "2024-01-31T10:23:24.029686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977bd04b-3cc6-4d50-96ba-4a24805d063b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:24.960783Z",
     "iopub.status.busy": "2024-01-31T10:23:24.960043Z",
     "iopub.status.idle": "2024-01-31T10:23:24.989565Z",
     "shell.execute_reply": "2024-01-31T10:23:24.989021Z",
     "shell.execute_reply.started": "2024-01-31T10:23:24.960752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import prepare_model_for_int8_training\n",
    "\n",
    "model = prepare_model_for_int8_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9ac474c-481a-464f-9472-5db748b193c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:26.931039Z",
     "iopub.status.busy": "2024-01-31T10:23:26.930633Z",
     "iopub.status.idle": "2024-01-31T10:23:26.935113Z",
     "shell.execute_reply": "2024-01-31T10:23:26.934243Z",
     "shell.execute_reply.started": "2024-01-31T10:23:26.931012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37a275b4-2bed-4efd-8ac9-93aac66984da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:28.517183Z",
     "iopub.status.busy": "2024-01-31T10:23:28.516579Z",
     "iopub.status.idle": "2024-01-31T10:23:28.754828Z",
     "shell.execute_reply": "2024-01-31T10:23:28.754230Z",
     "shell.execute_reply.started": "2024-01-31T10:23:28.517157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,932,160 || all params: 1,547,237,120 || trainable%: 0.25414074863974306\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fbe63ef-0f5c-47f1-a973-4a636c25412b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:29.867778Z",
     "iopub.status.busy": "2024-01-31T10:23:29.867368Z",
     "iopub.status.idle": "2024-01-31T10:23:29.892854Z",
     "shell.execute_reply": "2024-01-31T10:23:29.892276Z",
     "shell.execute_reply.started": "2024-01-31T10:23:29.867751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# 设置序列到序列模型训练的参数\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/whisper-large-v2-asr-int8\",  # 指定模型输出和保存的目录\n",
    "    per_device_train_batch_size=batch_size,  # 每个设备上的训练批量大小\n",
    "    gradient_accumulation_steps=1,  # 梯度累积步数，在每次优化器步骤之前累积的更新步数\n",
    "    learning_rate=1e-3,  # 学习率\n",
    "    warmup_steps=50,  # 在训练初期增加学习率的步数，有助于稳定训练\n",
    "    #max_steps=100, # 训练总步数\n",
    "    num_train_epochs=3,  # 训练的总轮数\n",
    "    evaluation_strategy=\"epoch\",  # 设置评估策略，这里是在每个epoch结束时进行评估\n",
    "    fp16=False,  # 启用混合精度训练，可以提高训练速度，同时减少内存使用\n",
    "    per_device_eval_batch_size=batch_size,  # 每个设备上的评估批量大小\n",
    "    generation_max_length=128,  # 生成任务的最大长度\n",
    "    logging_steps=25,  # 指定日志记录的步骤，用于跟踪训练进度\n",
    "    remove_unused_columns=False,  # 是否删除不使用的列，以减少数据处理开销\n",
    "    label_names=[\"labels\"],  # 指定标签列的名称，用于训练过程中\n",
    "    save_total_limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab53963-a1e2-4827-9bd9-a4cad9c950a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:30.773925Z",
     "iopub.status.busy": "2024-01-31T10:23:30.773332Z",
     "iopub.status.idle": "2024-01-31T10:23:30.919856Z",
     "shell.execute_reply": "2024-01-31T10:23:30.919240Z",
     "shell.execute_reply.started": "2024-01-31T10:23:30.773896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "from transformers import Seq2SeqTrainer, TrainerCallback, Seq2SeqTrainingArguments, TrainerState, TrainerControl\n",
    "\n",
    "class SavePeftModelCallback(TrainerCallback):\n",
    "    def on_save(\n",
    "        self,\n",
    "        args: Seq2SeqTrainingArguments,\n",
    "        state: TrainerState,\n",
    "        control: TrainerControl,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        checkpoint_folder = os.path.join(args.output_dir, f\"{PREFIX_CHECKPOINT_DIR}-{state.global_step}\")\n",
    "\n",
    "        peft_model_path = os.path.join(checkpoint_folder, \"adapter_model\")\n",
    "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
    "\n",
    "        pytorch_model_path = os.path.join(checkpoint_folder, \"pytorch_model.bin\")\n",
    "        if os.path.exists(pytorch_model_path):\n",
    "            os.remove(pytorch_model_path)\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2b60bab-630b-4c00-aef6-d98071c45ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:31.561485Z",
     "iopub.status.busy": "2024-01-31T10:23:31.560373Z",
     "iopub.status.idle": "2024-01-31T10:23:31.564885Z",
     "shell.execute_reply": "2024-01-31T10:23:31.564285Z",
     "shell.execute_reply.started": "2024-01-31T10:23:31.561452Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53f9b24-2451-48f2-b809-f01456fa5343",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:32.344427Z",
     "iopub.status.busy": "2024-01-31T10:23:32.343859Z",
     "iopub.status.idle": "2024-01-31T10:23:32.361454Z",
     "shell.execute_reply": "2024-01-31T10:23:32.360939Z",
     "shell.execute_reply.started": "2024-01-31T10:23:32.344404Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[SavePeftModelCallback],\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fddc8-d16e-440a-a4ed-4954c793e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2000\n",
    "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0a88793-8ead-46ff-bf02-cf220ab48a12",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T10:23:34.319348Z",
     "iopub.status.busy": "2024-01-31T10:23:34.318945Z",
     "iopub.status.idle": "2024-01-31T14:14:20.734132Z",
     "shell.execute_reply": "2024-01-31T14:14:20.729513Z",
     "shell.execute_reply.started": "2024-01-31T10:23:34.319323Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='909' max='2724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 909/2724 3:48:22 < 7:37:00, 0.07 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8/331 01:29 < 1:08:39, 0.08 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacty of 15.78 GiB of which 997.75 MiB is free. Process 5644 has 14.80 GiB memory in use. Of the allocated memory 10.83 GiB is allocated by PyTorch, and 2.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/whisper-large-v2-asr-int8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer.py:1944\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2287\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2289\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2292\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer_seq2seq.py:166\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer.py:3085\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3082\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3084\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3085\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3095\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer.py:3300\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3298\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[1;32m   3299\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[0;32m-> 3300\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3303\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:121\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    118\u001b[0m     new_tensors\n\u001b[1;32m    119\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:121\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    118\u001b[0m     new_tensors\n\u001b[1;32m    119\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:123\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    126\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    127\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:82\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     79\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     85\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacty of 15.78 GiB of which 997.75 MiB is free. Process 5644 has 14.80 GiB memory in use. Of the allocated memory 10.83 GiB is allocated by PyTorch, and 2.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(\"models/whisper-large-v2-asr-int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7981af-0824-4062-971a-71dd7761bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"models/whisper-large-v2-asr-int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f52aa9-589f-4c15-aad8-1b928f0651cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978765d8-dfec-44c0-8453-180c8e4610a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:32:02.528082Z",
     "iopub.status.busy": "2024-01-31T16:32:02.527349Z",
     "iopub.status.idle": "2024-01-31T16:32:02.531095Z",
     "shell.execute_reply": "2024-01-31T16:32:02.530422Z",
     "shell.execute_reply.started": "2024-01-31T16:32:02.528054Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_audio = \"data/learn-english.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e498c7bd-0eeb-4f57-8086-9410de4250e5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T15:44:21.818886Z",
     "iopub.status.busy": "2024-01-31T15:44:21.818464Z",
     "iopub.status.idle": "2024-01-31T15:44:21.872540Z",
     "shell.execute_reply": "2024-01-31T15:44:21.871735Z",
     "shell.execute_reply.started": "2024-01-31T15:44:21.818861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before clearing cache:\n",
      "1.74 GB\n",
      "1.74 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Before clearing cache:\\n{torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB\")\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"{torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f91758a-3b4a-43f2-8f8c-2ff7ef30770d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-31T16:33:17.001745Z",
     "iopub.status.busy": "2024-01-31T16:33:17.001487Z",
     "iopub.status.idle": "2024-01-31T16:33:21.937673Z",
     "shell.execute_reply": "2024-01-31T16:33:21.937024Z",
     "shell.execute_reply.started": "2024-01-31T16:33:17.001725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "\n",
    "#model = \"/mnt/workspace/models/whisper-large-v2-asr-int8/checkpoint-500\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"/mnt/workspace/models/whisper-large-v2-asr-int8/checkpoint-500\", load_in_8bit=True, device_map=\"auto\")\n",
    "\n",
    "pipeline = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
    "\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"chinese\", task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1945cb-8b24-43bd-b6bf-f6ca661ee5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:33:34.974198Z",
     "iopub.status.busy": "2024-01-31T16:33:34.973789Z",
     "iopub.status.idle": "2024-01-31T16:33:50.374440Z",
     "shell.execute_reply": "2024-01-31T16:33:50.373797Z",
     "shell.execute_reply.started": "2024-01-31T16:33:34.974175Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    text = pipeline(test_audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d87e2b-9ac4-481d-8e36-0cf8c09c878a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:33:53.820235Z",
     "iopub.status.busy": "2024-01-31T16:33:53.819804Z",
     "iopub.status.idle": "2024-01-31T16:33:53.826561Z",
     "shell.execute_reply": "2024-01-31T16:33:53.825996Z",
     "shell.execute_reply.started": "2024-01-31T16:33:53.820203Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"! Hello mom Hello Karr Hello mommy OK let's review What's the title of the story? What does Dina have? Dina has a dog Dina has a dog! Dinah has a... Dinah has a... dog! Dinah has a... sister! Dinah has a... brother!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5567787f-ead6-4fc6-b6a2-2f929861e8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:20:47.785120Z",
     "iopub.status.busy": "2024-01-31T16:20:47.784713Z",
     "iopub.status.idle": "2024-01-31T16:21:03.380279Z",
     "shell.execute_reply": "2024-01-31T16:21:03.379526Z",
     "shell.execute_reply.started": "2024-01-31T16:20:47.785096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    text = pipeline(test_audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "971374b3-ac8b-42c0-9a73-a67ea20a78de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:21:05.297062Z",
     "iopub.status.busy": "2024-01-31T16:21:05.296452Z",
     "iopub.status.idle": "2024-01-31T16:21:05.300990Z",
     "shell.execute_reply": "2024-01-31T16:21:05.300464Z",
     "shell.execute_reply.started": "2024-01-31T16:21:05.297032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"! Hello mom Hello Carl Hello mommy OK let's review What's the title of the story? What does Dina have? Dina has a dog Dina has a dog Dina has a dog! Dinah has a... Dinah has a... dog! Dinah has a... sister! Dinah has a... brother!\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f4ef2-b931-48d7-80bc-87baf5ac187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8824b4ec-739a-49a6-994c-07711d908d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:34:05.513295Z",
     "iopub.status.busy": "2024-01-31T16:34:05.512866Z",
     "iopub.status.idle": "2024-01-31T16:34:05.525901Z",
     "shell.execute_reply": "2024-01-31T16:34:05.525294Z",
     "shell.execute_reply.started": "2024-01-31T16:34:05.513269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# 词错误率（WER）是评估ASR模型常用的指标。从 Evaluate加载 WER 指标\n",
    "metric = evaluate.load(\"/mnt/workspace/evaluate/metrics/wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6bfe88-7019-43e8-a9c9-b39e5c10d6f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:34:08.559745Z",
     "iopub.status.busy": "2024-01-31T16:34:08.559144Z",
     "iopub.status.idle": "2024-01-31T16:34:08.586349Z",
     "shell.execute_reply": "2024-01-31T16:34:08.585804Z",
     "shell.execute_reply.started": "2024-01-31T16:34:08.559719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (q_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (q_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (q_proj): lora.Linear8bitLt(\n",
       "              (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d07e6a9d-d84c-4d9c-8bcb-4377feb03697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T16:34:27.053400Z",
     "iopub.status.busy": "2024-01-31T16:34:27.052978Z",
     "iopub.status.idle": "2024-01-31T20:09:03.105627Z",
     "shell.execute_reply": "2024-01-31T20:09:03.105021Z",
     "shell.execute_reply.started": "2024-01-31T16:34:27.053374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1323/1323 [3:34:36<00:00,  9.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = (\n",
    "                model.generate(\n",
    "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
    "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),\n",
    "                    max_new_tokens=255,\n",
    "                )\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            metric.add_batch(\n",
    "                predictions=decoded_preds,\n",
    "                references=decoded_labels,\n",
    "            )\n",
    "    del generated_tokens, labels, batch\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a79f35e-a590-4bb5-9500-ddb528b1f7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T20:09:03.108957Z",
     "iopub.status.busy": "2024-01-31T20:09:03.108758Z",
     "iopub.status.idle": "2024-01-31T20:09:03.420217Z",
     "shell.execute_reply": "2024-01-31T20:09:03.419633Z",
     "shell.execute_reply.started": "2024-01-31T20:09:03.108937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer=61.47231147231147\n"
     ]
    }
   ],
   "source": [
    "wer = 100 * metric.compute()\n",
    "print(f\"{wer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47e27f-2821-4569-8c71-742c133a7632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d606b037-fdbe-4e65-ac0a-94cae5d9af7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:43:40.477802Z",
     "iopub.status.busy": "2024-01-23T02:43:40.477392Z",
     "iopub.status.idle": "2024-01-23T02:43:40.484188Z",
     "shell.execute_reply": "2024-01-23T02:43:40.483298Z",
     "shell.execute_reply.started": "2024-01-23T02:43:40.477774Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533b5990-3417-422f-a704-622f16be39ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:08:52.782239Z",
     "iopub.status.busy": "2024-01-23T11:08:52.781687Z",
     "iopub.status.idle": "2024-01-23T11:08:52.788310Z",
     "shell.execute_reply": "2024-01-23T11:08:52.787634Z",
     "shell.execute_reply.started": "2024-01-23T11:08:52.782209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "squad_v2 = True\n",
    "model_checkpoint = \"/mnt/workspace/data/distilbert-base-uncased\" #\"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087112c9-a760-4889-8d6e-54617b497302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:08:54.135696Z",
     "iopub.status.busy": "2024-01-23T11:08:54.135111Z",
     "iopub.status.idle": "2024-01-23T11:08:56.276993Z",
     "shell.execute_reply": "2024-01-23T11:08:56.276333Z",
     "shell.execute_reply.started": "2024-01-23T11:08:54.135668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_parquet(\"/mnt/workspace/data/squad_v2/squad_v2/train-00000-of-00001.parquet\"),\n",
    "    \"test\": Dataset.from_parquet(\"/mnt/workspace/data/squad_v2/squad_v2/validation-00000-of-00001.parquet\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44a7036-8a8f-4e23-94e0-79b1488d2806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:08:59.139345Z",
     "iopub.status.busy": "2024-01-23T11:08:59.138535Z",
     "iopub.status.idle": "2024-01-23T11:08:59.146066Z",
     "shell.execute_reply": "2024-01-23T11:08:59.145458Z",
     "shell.execute_reply.started": "2024-01-23T11:08:59.139315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb7e212-a868-48fb-84c5-be61b7aa0c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:01.961279Z",
     "iopub.status.busy": "2024-01-23T11:09:01.960731Z",
     "iopub.status.idle": "2024-01-23T11:09:01.969189Z",
     "shell.execute_reply": "2024-01-23T11:09:01.968581Z",
     "shell.execute_reply.started": "2024-01-23T11:09:01.961252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54badf8d-d925-4ac6-bad5-c1e5ccb0e005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:02.762808Z",
     "iopub.status.busy": "2024-01-23T11:09:02.762206Z",
     "iopub.status.idle": "2024-01-23T11:09:02.769027Z",
     "shell.execute_reply": "2024-01-23T11:09:02.768405Z",
     "shell.execute_reply.started": "2024-01-23T11:09:02.762780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c3d055-551f-4544-95f5-cab9ed120a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:04.224537Z",
     "iopub.status.busy": "2024-01-23T11:09:04.224005Z",
     "iopub.status.idle": "2024-01-23T11:09:04.241391Z",
     "shell.execute_reply": "2024-01-23T11:09:04.240790Z",
     "shell.execute_reply.started": "2024-01-23T11:09:04.224507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ad17055645df0001a2d1b7e</td>\n",
       "      <td>Military_history_of_the_United_States</td>\n",
       "      <td>In the Treaty of Paris after the Revolution, the British had ceded the lands between the Appalachian Mountains and the Mississippi River to the United States, without consulting the Shawnee, Cherokee, Choctaw and other smaller tribes who lived there. Because many of the tribes had fought as allies of the British, the United States compelled tribal leaders to sign away lands in postwar treaties, and began dividing these lands for settlement. This provoked a war in the Northwest Territory in which the U.S. forces performed poorly; the Battle of the Wabash in 1791 was the most severe defeat ever suffered by the United States at the hands of American Indians. President Washington dispatched a newly trained army to the region, which decisively defeated the Indian confederacy at the Battle of Fallen Timbers in 1794.</td>\n",
       "      <td>When was this deciding battle postponed?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5730ba682461fd1900a9d002</td>\n",
       "      <td>Russian_language</td>\n",
       "      <td>Russian distinguishes between consonant phonemes with palatal secondary articulation and those without, the so-called soft and hard sounds. This distinction is found between pairs of almost all consonants and is one of the most distinguishing features of the language. Another important aspect is the reduction of unstressed vowels. Stress, which is unpredictable, is not normally indicated orthographically though an optional acute accent (знак ударения, znak udareniya) may be used to mark stress, such as to distinguish between homographic words, for example замо́к (zamok, meaning a lock) and за́мок (zamok, meaning a castle), or to indicate the proper pronunciation of uncommon words or names.</td>\n",
       "      <td>What word means both lock and castle, depending on its accent?</td>\n",
       "      <td>{'text': ['zamok'], 'answer_start': [570]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5726dc19dd62a815002e92ff</td>\n",
       "      <td>Korean_War</td>\n",
       "      <td>With Lieutenant-General Matthew Ridgway assuming the command of the U.S. Eighth Army on 26 December, the PVA and the KPA launched their Third Phase Offensive (also known as the \"Chinese New Year's Offensive\") on New Year's Eve of 1950. Utilizing night attacks in which UN Command fighting positions were encircled and then assaulted by numerically superior troops who had the element of surprise, the attacks were accompanied by loud trumpets and gongs, which fulfilled the double purpose of facilitating tactical communication and mentally disorienting the enemy. UN forces initially had no familiarity with this tactic, and as a result some soldiers panicked, abandoning their weapons and retreating to the south. The Chinese New Year's Offensive overwhelmed UN forces, allowing the PVA and KPA to conquer Seoul for the second time on 4 January 1951.</td>\n",
       "      <td>Why goals were accomplished the the KPA and PVA's use gongs during these attacks?</td>\n",
       "      <td>{'text': ['facilitating tactical communication and mentally disorienting the enemy'], 'answer_start': [492]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56fa2d76f34c681400b0bfed</td>\n",
       "      <td>Wood</td>\n",
       "      <td>In the case of the ring-porous hardwoods there seems to exist a pretty definite relation between the rate of growth of timber and its properties. This may be briefly summed up in the general statement that the more rapid the growth or the wider the rings of growth, the heavier, harder, stronger, and stiffer the wood. This, it must be remembered, applies only to ring-porous woods such as oak, ash, hickory, and others of the same group, and is, of course, subject to some exceptions and limitations.</td>\n",
       "      <td>Ring-porous hardwoods have a clear relationship between their properties and what other factor?</td>\n",
       "      <td>{'text': ['rate of growth'], 'answer_start': [101]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5aceb3b432bba1001ae4b0d1</td>\n",
       "      <td>Jews</td>\n",
       "      <td>More than half of the Jews live in the Diaspora (see Population table). Currently, the largest Jewish community outside Israel, and either the largest or second-largest Jewish community in the world, is located in the United States, with 5.2 million to 6.4 million Jews by various estimates. Elsewhere in the Americas, there are also large Jewish populations in Canada (315,000), Argentina (180,000-300,000), and Brazil (196,000-600,000), and smaller populations in Mexico, Uruguay, Venezuela, Chile, Colombia and several other countries (see History of the Jews in Latin America). Demographers disagree on whether the United States has a larger Jewish population than Israel, with many maintaining that Israel surpassed the United States in Jewish population during the 2000s, while others maintain that the United States still has the largest Jewish population in the world. Currently, a major national Jewish population survey is planned to ascertain whether or not Israel has overtaken the United States in Jewish population.</td>\n",
       "      <td>How many Jews live in Mexico?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5ad27d08d7d075001a4296ac</td>\n",
       "      <td>House_music</td>\n",
       "      <td>Larry Heard, a.k.a. \"Mr. Fingers\", claims that the term \"house\" became popular due to many of the early DJs creating music in their own homes using synthesizers and drum machines such as the Roland TR-808, TR-909, and the TB 303.[citation needed] These synthesizers were used to create a house subgenre called acid house.</td>\n",
       "      <td>What are the Fingers TR-808, TR-909, and TB 303 examples of?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>571a782d10f8ca140030506b</td>\n",
       "      <td>Memory</td>\n",
       "      <td>Sleep does not affect acquisition or recall while one is awake. Therefore, sleep has the greatest effect on memory consolidation. During sleep, the neural connections in the brain are strengthened. This enhances the brain’s abilities to stabilize and retain memories. There have been several studies which show that sleep improves the retention of memory, as memories are enhanced through active consolidation. System consolidation takes place during slow-wave sleep (SWS). This process implicates that memories are reactivated during sleep, but that the process doesn’t enhance every memory. It also implicates that qualitative changes are made to the memories when they are transferred to long-term store during sleep. When you are sleeping, the hippocampus replays the events of the day for the neocortex. The neocortex then reviews and processes memories, which moves them into long-term memory. When you do not get enough sleep it makes it more difficult to learn as these neural connections are not as strong, resulting in a lower retention rate of memories. Sleep deprivation makes it harder to focus, resulting in inefficient learning. Furthermore, some studies have shown that sleep deprivation can lead to false memories as the memories are not properly transferred to long-term memory. Therefore, it is important to get the proper amount of sleep so that memory can function at the highest level. One of the primary functions of sleep is thought to be the improvement of the consolidation of information, as several studies have demonstrated that memory depends on getting sufficient sleep between training and test. Additionally, data obtained from neuroimaging studies have shown activation patterns in the sleeping brain that mirror those recorded during the learning of tasks from the previous day, suggesting that new memories may be solidified through such rehearsal.</td>\n",
       "      <td>In studies what is a relationship between sleeping and learning?</td>\n",
       "      <td>{'text': ['activation patterns in the sleeping brain that mirror those recorded during the learning of tasks from the previous day'], 'answer_start': [1693]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56de4d9ecffd8e1900b4b7e3</td>\n",
       "      <td>Institute_of_technology</td>\n",
       "      <td>The world's first institution of technology or technical university with tertiary technical education is the Banská Akadémia in Banská Štiavnica, Slovakia, founded in 1735, Academy since December 13, 1762 established by queen Maria Theresa in order to train specialists of silver and gold mining and metallurgy in neighbourhood. Teaching started in 1764. Later the department of Mathematics, Mechanics and Hydraulics and department of Forestry were settled. University buildings are still at their place today and are used for teaching. University has launched the first book of electrotechnics in the world.</td>\n",
       "      <td>The Banská Akadémia was originally intended for training workers in what two precious metals?</td>\n",
       "      <td>{'text': ['silver and gold'], 'answer_start': [273]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5a7a4f4017ab25001a8a04c3</td>\n",
       "      <td>Literature</td>\n",
       "      <td>In the Age of Reason philosophical tracts and speculations on history and human nature integrated literature with social and political developments. The inevitable reaction was the explosion of Romanticism in the later 18th century which reclaimed the imaginative and fantastical bias of old romances and folk-literature and asserted the primacy of individual experience and emotion. But as the 19th-century went on, European fiction evolved towards realism and naturalism, the meticulous documentation of real life and social trends. Much of the output of naturalism was implicitly polemical, and influenced social and political change, but 20th century fiction and drama moved back towards the subjective, emphasising unconscious motivations and social and environmental pressures on the individual. Writers such as Proust, Eliot, Joyce, Kafka and Pirandello exemplify the trend of documenting internal rather than external realities.</td>\n",
       "      <td>As the 18th century went on, European fiction evolved toward what?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5acea6ec32bba1001ae4af01</td>\n",
       "      <td>Jews</td>\n",
       "      <td>Ashkenazi Jews represent the bulk of modern Jewry, with at least 70% of Jews worldwide (and up to 90% prior to World War II and the Holocaust). As a result of their emigration from Europe, Ashkenazim also represent the overwhelming majority of Jews in the New World continents, in countries such as the United States, Canada, Argentina, Australia, and Brazil. In France, the immigration of Jews from Algeria (Sephardim) has led them to outnumber the Ashkenazim. Only in Israel is the Jewish population representative of all groups, a melting pot independent of each group's proportion within the overall world Jewish population.</td>\n",
       "      <td>Who represents the minority of modern Jewry?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793b026c-35a5-4dcc-bc23-302ba8c9539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:06.015979Z",
     "iopub.status.busy": "2024-01-23T11:09:06.015474Z",
     "iopub.status.idle": "2024-01-23T11:09:09.162437Z",
     "shell.execute_reply": "2024-01-23T11:09:09.161703Z",
     "shell.execute_reply.started": "2024-01-23T11:09:06.015952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e235cec-d79b-4000-a40e-2038cea26951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:13.646656Z",
     "iopub.status.busy": "2024-01-23T11:09:13.645934Z",
     "iopub.status.idle": "2024-01-23T11:09:13.650214Z",
     "shell.execute_reply": "2024-01-23T11:09:13.649510Z",
     "shell.execute_reply.started": "2024-01-23T11:09:13.646625Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1c91f8-b455-4041-94ae-acaa5da4878b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:20.499414Z",
     "iopub.status.busy": "2024-01-23T11:09:20.498779Z",
     "iopub.status.idle": "2024-01-23T11:09:20.505847Z",
     "shell.execute_reply": "2024-01-23T11:09:20.505254Z",
     "shell.execute_reply.started": "2024-01-23T11:09:20.499381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344bf1ea-6c38-4db0-8bb7-8b253f5b1490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:23.400376Z",
     "iopub.status.busy": "2024-01-23T11:09:23.399900Z",
     "iopub.status.idle": "2024-01-23T11:09:23.410998Z",
     "shell.execute_reply": "2024-01-23T11:09:23.410387Z",
     "shell.execute_reply.started": "2024-01-23T11:09:23.400349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # 一些问题的左侧可能有很多空白字符，这对我们没有用，而且会导致上下文的截断失败\n",
    "    # （标记化的问题将占用大量空间）。因此，我们删除左侧的空白字符。\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和填充对我们的示例进行标记化，但保留溢出部分，使用步幅（stride）。\n",
    "    # 当上下文很长时，这会导致一个示例可能提供多个特征，其中每个特征的上下文都与前一个特征的上下文有一些重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例可能给我们提供多个特征（如果它具有很长的上下文），我们需要一个从特征到其对应示例的映射。这个键就提供了这个映射关系。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # 偏移映射将为我们提供从令牌到原始上下文中的字符位置的映射。这将帮助我们计算开始位置和结束位置。\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    # 让我们为这些示例进行标记！\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # 我们将使用CLS令牌的索引来标记不可能的答案。\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # 获取与该示例对应的序列（以了解上下文和问题是什么）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 一个示例可以提供多个跨度，这是包含此文本跨度的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # 如果没有给出答案，则将cls_index设置为答案。\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # 答案在文本中的开始和结束字符索引。\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # 当前跨度在文本中的开始令牌索引。\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # 当前跨度在文本中的结束令牌索引。\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 检测答案是否超出跨度（在这种情况下，该特征的标签将使用CLS索引）。\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # 否则，将token_start_index和token_end_index移到答案的两端。\n",
    "                # 注意：如果答案是最后一个单词（边缘情况），我们可以在最后一个偏移之后继续。\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6dd9e2-56fb-47a4-a839-929252646c50",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:25.049400Z",
     "iopub.status.busy": "2024-01-23T11:09:25.048898Z",
     "iopub.status.idle": "2024-01-23T11:09:25.052962Z",
     "shell.execute_reply": "2024-01-23T11:09:25.052165Z",
     "shell.execute_reply.started": "2024-01-23T11:09:25.049376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The maximum length of a feature (question and context)\n",
    "max_length = 384 \n",
    "# The authorized overlap between two part of the context when splitting it is needed.\n",
    "doc_stride = 128 \n",
    "\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590702ff-ae8a-4b3e-89ae-d6bd740a6b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:28.574682Z",
     "iopub.status.busy": "2024-01-23T11:09:28.574069Z",
     "iopub.status.idle": "2024-01-23T11:09:33.374208Z",
     "shell.execute_reply": "2024-01-23T11:09:33.373522Z",
     "shell.execute_reply.started": "2024-01-23T11:09:28.574656Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11873/11873 [00:04<00:00, 2626.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(prepare_train_features,\n",
    "                                  batched=True,\n",
    "                                  remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edfe1611-93e5-4c94-aad1-1a73ffd73713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:35.429705Z",
     "iopub.status.busy": "2024-01-23T11:09:35.428867Z",
     "iopub.status.idle": "2024-01-23T11:09:41.540508Z",
     "shell.execute_reply": "2024-01-23T11:09:41.539749Z",
     "shell.execute_reply.started": "2024-01-23T11:09:35.429665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 19:09:37.681362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 19:09:39.323456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at /mnt/workspace/data/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4270121e-f7ec-4323-8595-600f8ea82a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:45.487681Z",
     "iopub.status.busy": "2024-01-23T11:09:45.486696Z",
     "iopub.status.idle": "2024-01-23T11:09:45.496596Z",
     "shell.execute_reply": "2024-01-23T11:09:45.495874Z",
     "shell.execute_reply.started": "2024-01-23T11:09:45.487648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "model_dir = \"models\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_dir}/{model_name}-finetuned-squad-v2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa4cdb9b-9212-42f1-b44d-7798b34b1d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:49.064955Z",
     "iopub.status.busy": "2024-01-23T11:09:49.064407Z",
     "iopub.status.idle": "2024-01-23T11:09:49.068419Z",
     "shell.execute_reply": "2024-01-23T11:09:49.067658Z",
     "shell.execute_reply.started": "2024-01-23T11:09:49.064927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38294a8a-b819-4656-b705-15e9449e9db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:09:51.381614Z",
     "iopub.status.busy": "2024-01-23T11:09:51.380949Z",
     "iopub.status.idle": "2024-01-23T11:09:56.460975Z",
     "shell.execute_reply": "2024-01-23T11:09:56.460254Z",
     "shell.execute_reply.started": "2024-01-23T11:09:51.381579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d590feec-78e9-4cf2-83f5-d91d38534b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T11:10:02.197794Z",
     "iopub.status.busy": "2024-01-23T11:10:02.197178Z",
     "iopub.status.idle": "2024-01-23T12:20:13.738236Z",
     "shell.execute_reply": "2024-01-23T12:20:13.737360Z",
     "shell.execute_reply.started": "2024-01-23T11:10:02.197769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6177' max='6177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6177/6177 1:10:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.328391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.178900</td>\n",
       "      <td>1.268901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.051000</td>\n",
       "      <td>1.340030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory models/distilbert-base-uncased-finetuned-squad-v2/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory models/distilbert-base-uncased-finetuned-squad-v2/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory models/distilbert-base-uncased-finetuned-squad-v2/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6177, training_loss=1.3649238486380297, metrics={'train_runtime': 4211.2541, 'train_samples_per_second': 93.859, 'train_steps_per_second': 1.467, 'total_flos': 3.873165421863629e+16, 'train_loss': 1.3649238486380297, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f89aa7c2-8f6f-4fa5-a321-ba50545daea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:28.689876Z",
     "iopub.status.busy": "2024-01-23T12:33:28.689241Z",
     "iopub.status.idle": "2024-01-23T12:33:28.693165Z",
     "shell.execute_reply": "2024-01-23T12:33:28.692474Z",
     "shell.execute_reply.started": "2024-01-23T12:33:28.689848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model_path = f\"{model_dir}/{model_name}-finetuned-squad-v2-trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fce3d88-e741-4031-9f64-ca5e11c231de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:37.278277Z",
     "iopub.status.busy": "2024-01-23T12:33:37.277818Z",
     "iopub.status.idle": "2024-01-23T12:33:37.857784Z",
     "shell.execute_reply": "2024-01-23T12:33:37.857086Z",
     "shell.execute_reply.started": "2024-01-23T12:33:37.278247Z"
    }
   },
   "outputs": [],
   "source": [
    "model_to_save = trainer.save_model(trained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b6f2d-e4b8-47a9-ba91-77d67ac51f57",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24349b86-319b-4c66-94ed-2cfe0d162b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:41.411193Z",
     "iopub.status.busy": "2024-01-23T12:33:41.410698Z",
     "iopub.status.idle": "2024-01-23T12:33:41.486529Z",
     "shell.execute_reply": "2024-01-23T12:33:41.485936Z",
     "shell.execute_reply.started": "2024-01-23T12:33:41.411163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = trainer.model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebeaf2e2-6acb-4902-8b19-2d40d0eaa61e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:44.809790Z",
     "iopub.status.busy": "2024-01-23T12:33:44.809254Z",
     "iopub.status.idle": "2024-01-23T12:33:44.814989Z",
     "shell.execute_reply": "2024-01-23T12:33:44.814134Z",
     "shell.execute_reply.started": "2024-01-23T12:33:44.809756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 384]), torch.Size([64, 384]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9cd5877-5870-4dd2-8959-5c11966d5e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:49.270627Z",
     "iopub.status.busy": "2024-01-23T12:33:49.270118Z",
     "iopub.status.idle": "2024-01-23T12:33:49.280206Z",
     "shell.execute_reply": "2024-01-23T12:33:49.279497Z",
     "shell.execute_reply.started": "2024-01-23T12:33:49.270602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 49,  37,  72,  80, 157,  17,  44,   0, 148, 202, 119,  52,  22,  31,\n",
       "           0, 120,   0,   0,  90,   0,   0,  56,  88, 152,  23,   0,   0, 139,\n",
       "           0,  51, 143,   0,  72,  32,   0,   0,  93,  25,  93, 105,  41,  13,\n",
       "          33,  55,  99,  29,  80,   0,  28,  29,   0,   0, 139,  70,  49,   0,\n",
       "          48,  62,  75,   0,  16,   0,   0,  12], device='cuda:0'),\n",
       " tensor([ 49,  40,  76,  81, 157,  19,  44,   0, 153, 204, 120,  52,  26,  33,\n",
       "           0, 121,   0,   0,  91,   0,   0,  56,  94, 153,  24,   0,   0, 142,\n",
       "          16,  52, 154,   0,  72,  32,   0,   0,  94,  27,  94, 128,  58,  15,\n",
       "          50,  56, 100,  30,  81, 143,  29,  30,   0,  80, 141,  71,  51,   0,\n",
       "          49,  63,  82,   0,  17,   0,   0,  15], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d354da-d6b3-4fec-abe4-7c0d3622db5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:52.827944Z",
     "iopub.status.busy": "2024-01-23T12:33:52.827307Z",
     "iopub.status.idle": "2024-01-23T12:33:52.831411Z",
     "shell.execute_reply": "2024-01-23T12:33:52.830496Z",
     "shell.execute_reply.started": "2024-01-23T12:33:52.827918Z"
    }
   },
   "outputs": [],
   "source": [
    "n_best_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2f3701-522e-43ef-990e-351f81e6e816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:55.761404Z",
     "iopub.status.busy": "2024-01-23T12:33:55.760615Z",
     "iopub.status.idle": "2024-01-23T12:33:55.768746Z",
     "shell.execute_reply": "2024-01-23T12:33:55.768130Z",
     "shell.execute_reply.started": "2024-01-23T12:33:55.761378Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "\n",
    "# 获取最佳的起始和结束位置的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "valid_answers = []\n",
    "\n",
    "# 遍历起始位置和结束位置的索引组合\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index:  # 需要进一步测试以检查答案是否在上下文中\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\"  # 我们需要找到一种方法来获取与上下文中答案对应的原始子字符串\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b1be96-c97c-4d18-90eb-ad1dcbaf9c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:57.769438Z",
     "iopub.status.busy": "2024-01-23T12:33:57.768770Z",
     "iopub.status.idle": "2024-01-23T12:33:57.775748Z",
     "shell.execute_reply": "2024-01-23T12:33:57.775075Z",
     "shell.execute_reply.started": "2024-01-23T12:33:57.769408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # 一些问题的左侧有很多空白，这些空白并不有用且会导致上下文截断失败（分词后的问题会占用很多空间）。\n",
    "    # 因此我们移除这些左侧空白\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和可能的填充对我们的示例进行分词，但使用步长保留溢出的令牌。这导致一个长上下文的示例可能产生\n",
    "    # 几个特征，每个特征的上下文都会稍微与前一个特征的上下文重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # 由于一个示例在上下文很长时可能会产生几个特征，我们需要一个从特征映射到其对应示例的映射。这个键就是为了这个目的。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # 我们保留产生这个特征的示例ID，并且会存储偏移映射。\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # 获取与该示例对应的序列（以了解哪些是上下文，哪些是问题）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # 一个示例可以产生几个文本段，这里是包含该文本段的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # 将不属于上下文的偏移映射设置为None，以便容易确定一个令牌位置是否属于上下文。\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4713acb-ad01-4de8-8a6f-60feaecdcdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:33:58.951910Z",
     "iopub.status.busy": "2024-01-23T12:33:58.951231Z",
     "iopub.status.idle": "2024-01-23T12:34:04.620795Z",
     "shell.execute_reply": "2024-01-23T12:34:04.620012Z",
     "shell.execute_reply.started": "2024-01-23T12:33:58.951885Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11873/11873 [00:05<00:00, 2101.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80aa3095-527f-43da-984a-b48b66d2860f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:34:06.931094Z",
     "iopub.status.busy": "2024-01-23T12:34:06.930440Z",
     "iopub.status.idle": "2024-01-23T12:34:52.033509Z",
     "shell.execute_reply": "2024-01-23T12:34:52.032748Z",
     "shell.execute_reply.started": "2024-01-23T12:34:06.931060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "023921bf-5dda-4270-960e-a9d283ddf531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:34:53.452631Z",
     "iopub.status.busy": "2024-01-23T12:34:53.451987Z",
     "iopub.status.idle": "2024-01-23T12:34:53.456966Z",
     "shell.execute_reply": "2024-01-23T12:34:53.456270Z",
     "shell.execute_reply.started": "2024-01-23T12:34:53.452603Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adcd6f72-a45b-44d9-8e10-f774d5b3f260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:34:55.988750Z",
     "iopub.status.busy": "2024-01-23T12:34:55.988011Z",
     "iopub.status.idle": "2024-01-23T12:34:55.992117Z",
     "shell.execute_reply": "2024-01-23T12:34:55.991360Z",
     "shell.execute_reply.started": "2024-01-23T12:34:55.988716Z"
    }
   },
   "outputs": [],
   "source": [
    "max_answer_length = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a65ee405-2334-4cfe-8a12-cf0de2407c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:34:58.895026Z",
     "iopub.status.busy": "2024-01-23T12:34:58.894465Z",
     "iopub.status.idle": "2024-01-23T12:34:58.908518Z",
     "shell.execute_reply": "2024-01-23T12:34:58.907787Z",
     "shell.execute_reply.started": "2024-01-23T12:34:58.894998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 13.974663, 'text': 'France'},\n",
       " {'score': 8.045149, 'text': 'France.'},\n",
       " {'score': 7.803161, 'text': 'a region in France'},\n",
       " {'score': 7.681691,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway'},\n",
       " {'score': 7.3048377, 'text': 'in France'},\n",
       " {'score': 6.758797, 'text': 'region in France'},\n",
       " {'score': 6.0515146, 'text': 'Normandy, a region in France'},\n",
       " {'score': 5.9596286,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark'},\n",
       " {'score': 5.8759336,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland'},\n",
       " {'score': 3.476342,\n",
       "  'text': 'French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': 3.3794808, 'text': ', a region in France'},\n",
       " {'score': 3.309464,\n",
       "  'text': 'in the 10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': 3.2047057, 'text': 'France. They were descended from Norse'},\n",
       " {'score': 2.8377647,\n",
       "  'text': 'Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': 2.7002745,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates'},\n",
       " {'score': 1.8736475, 'text': 'a region in France.'},\n",
       " {'score': 1.51019,\n",
       "  'text': 'a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway'},\n",
       " {'score': 1.3753244, 'text': 'in France.'},\n",
       " {'score': 1.0118668,\n",
       "  'text': 'in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway'},\n",
       " {'score': 0.8292839, 'text': 'region in France.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "\n",
    "# 第一个特征来自第一个示例。对于更一般的情况，我们需要将example_id匹配到一个示例索引\n",
    "context = datasets[\"test\"][0][\"context\"]\n",
    "\n",
    "# 收集最佳开始/结束逻辑的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # 我们需要细化这个测试，以检查答案是否在上下文中\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fcd5faa-32d0-4b3b-86e8-3bd07396faa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:35:03.206541Z",
     "iopub.status.busy": "2024-01-23T12:35:03.205892Z",
     "iopub.status.idle": "2024-01-23T12:35:03.211843Z",
     "shell.execute_reply": "2024-01-23T12:35:03.211122Z",
     "shell.execute_reply.started": "2024-01-23T12:35:03.206512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['France', 'France', 'France', 'France'],\n",
       " 'answer_start': [159, 159, 159, 159]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2af4938a-2337-4538-84fd-e559b1113c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:35:07.952676Z",
     "iopub.status.busy": "2024-01-23T12:35:07.952124Z",
     "iopub.status.idle": "2024-01-23T12:35:21.572140Z",
     "shell.execute_reply": "2024-01-23T12:35:21.571260Z",
     "shell.execute_reply.started": "2024-01-23T12:35:07.952646Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"test\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88b21f73-95a0-4ecc-9c34-79b8ab46cea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:35:38.227673Z",
     "iopub.status.busy": "2024-01-23T12:35:38.227003Z",
     "iopub.status.idle": "2024-01-23T12:35:38.327284Z",
     "shell.execute_reply": "2024-01-23T12:35:38.326572Z",
     "shell.execute_reply.started": "2024-01-23T12:35:38.227645Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"/mnt/workspace/evaluate/metrics/squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a1b2c80-0c30-4f6b-82e1-554841096d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:35:41.052926Z",
     "iopub.status.busy": "2024-01-23T12:35:41.052496Z",
     "iopub.status.idle": "2024-01-23T12:35:41.063611Z",
     "shell.execute_reply": "2024-01-23T12:35:41.062831Z",
     "shell.execute_reply.started": "2024-01-23T12:35:41.052897Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # 构建一个从示例到其对应特征的映射。\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # 我们需要填充的字典。\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # 日志记录。\n",
    "    print(f\"正在后处理 {len(examples)} 个示例的预测，这些预测分散在 {len(features)} 个特征中。\")\n",
    "\n",
    "    # 遍历所有示例！\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # 这些是与当前示例关联的特征的索引。\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None # 仅在squad_v2为True时使用。\n",
    "        valid_answers = []\n",
    "        context = example[\"context\"]\n",
    "        # 遍历与当前示例关联的所有特征。\n",
    "        for feature_index in feature_indices:\n",
    "            # 我们获取模型对这个特征的预测。\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # 这将允许我们将logits中的某些位置映射到原始上下文中的文本跨度。\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # 更新最小空预测。\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # 浏览所有的最佳开始和结束logits，为 `n_best_size` 个最佳选择。\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # 在极少数情况下我们没有一个非空预测，我们创建一个假预测以避免失败。\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # 选择我们的最终答案：最佳答案或空答案（仅适用于squad_v2）\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934a839f-a76e-46dd-822d-c78f2305e138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:35:42.644647Z",
     "iopub.status.busy": "2024-01-23T12:35:42.644031Z",
     "iopub.status.idle": "2024-01-23T12:36:25.774543Z",
     "shell.execute_reply": "2024-01-23T12:36:25.773691Z",
     "shell.execute_reply.started": "2024-01-23T12:35:42.644621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在后处理 11873 个示例的预测，这些预测分散在 12134 个特征中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11873/11873 [00:30<00:00, 394.22it/s]\n"
     ]
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"test\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f95a833e-d88e-4bda-920e-ff06977fd154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T12:36:28.894641Z",
     "iopub.status.busy": "2024-01-23T12:36:28.893971Z",
     "iopub.status.idle": "2024-01-23T12:36:31.194675Z",
     "shell.execute_reply": "2024-01-23T12:36:31.193771Z",
     "shell.execute_reply.started": "2024-01-23T12:36:28.894612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 60.77655184030995,\n",
       " 'f1': 64.25639211398462,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 63.630229419703106,\n",
       " 'HasAns_f1': 70.59988926608264,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 57.93103448275862,\n",
       " 'NoAns_f1': 57.93103448275862,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 60.78497431146298,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 64.25679318403968,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"test\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4713a-7060-4535-9f85-9d3ee2f956fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "trans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

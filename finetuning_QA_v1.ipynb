{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2f2ea2-bd04-4d29-8def-3ab9afae6e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T08:57:05.426350Z",
     "iopub.status.busy": "2024-01-16T08:57:05.425806Z",
     "iopub.status.idle": "2024-01-16T08:57:05.430047Z",
     "shell.execute_reply": "2024-01-16T08:57:05.429233Z",
     "shell.execute_reply.started": "2024-01-16T08:57:05.426318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f26097-8d9a-47bd-bf2c-0fe38d8161fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T09:02:39.119345Z",
     "iopub.status.busy": "2024-01-16T09:02:39.118737Z",
     "iopub.status.idle": "2024-01-16T09:02:39.123255Z",
     "shell.execute_reply": "2024-01-16T09:02:39.122448Z",
     "shell.execute_reply.started": "2024-01-16T09:02:39.119320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c8dde0-4b54-4aba-98a9-a92ed2566345",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T02:31:42.163539Z",
     "iopub.status.busy": "2024-01-23T02:31:42.162824Z",
     "iopub.status.idle": "2024-01-23T02:31:42.166767Z",
     "shell.execute_reply": "2024-01-23T02:31:42.166016Z",
     "shell.execute_reply.started": "2024-01-23T02:31:42.163513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据你使用的模型和GPU资源情况，调整以下关键参数\n",
    "squad_v2 = False\n",
    "model_checkpoint = \"/mnt/workspace/data/distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f1ebb0-51ef-4aaa-b612-68d79271c6e5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T02:13:35.636952Z",
     "iopub.status.busy": "2024-01-23T02:13:35.636551Z",
     "iopub.status.idle": "2024-01-23T02:13:37.860491Z",
     "shell.execute_reply": "2024-01-23T02:13:37.859775Z",
     "shell.execute_reply.started": "2024-01-23T02:13:35.636924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_parquet(\"/mnt/workspace/data/squad/plain_text/train-00000-of-00001.parquet\"),\n",
    "    \"test\": Dataset.from_parquet(\"/mnt/workspace/data/squad/plain_text/validation-00000-of-00001.parquet\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2d62d7-d276-4a06-99dd-f53d8fe5cbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:13:47.257690Z",
     "iopub.status.busy": "2024-01-23T02:13:47.257116Z",
     "iopub.status.idle": "2024-01-23T02:13:47.264143Z",
     "shell.execute_reply": "2024-01-23T02:13:47.263494Z",
     "shell.execute_reply.started": "2024-01-23T02:13:47.257650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb4b96b-d618-4023-9f79-87b42d917c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:14:08.435161Z",
     "iopub.status.busy": "2024-01-23T02:14:08.434764Z",
     "iopub.status.idle": "2024-01-23T02:14:08.440189Z",
     "shell.execute_reply": "2024-01-23T02:14:08.439599Z",
     "shell.execute_reply.started": "2024-01-23T02:14:08.435135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2fe3f4-1870-4c1d-8699-ca629cf2e16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:14:15.038714Z",
     "iopub.status.busy": "2024-01-23T02:14:15.038270Z",
     "iopub.status.idle": "2024-01-23T02:14:15.045144Z",
     "shell.execute_reply": "2024-01-23T02:14:15.044505Z",
     "shell.execute_reply.started": "2024-01-23T02:14:15.038683Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa8a81c-6661-4a0a-b125-1743a6a43069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:14:17.897487Z",
     "iopub.status.busy": "2024-01-23T02:14:17.896768Z",
     "iopub.status.idle": "2024-01-23T02:14:17.914877Z",
     "shell.execute_reply": "2024-01-23T02:14:17.914276Z",
     "shell.execute_reply.started": "2024-01-23T02:14:17.897456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56d677f31c85041400947145</td>\n",
       "      <td>2008_Sichuan_earthquake</td>\n",
       "      <td>An article in Science suggested that the construction and filling of the Zipingpu Dam may have triggered the earthquake. The chief engineer of the Sichuan Geology and Mineral Bureau said that the sudden shift of a huge quantity of water into the region could have relaxed the tension between the two sides of the fault, allowing them to move apart, and could have increased the direct pressure on it, causing a violent rupture. The effect was \"25 times more\" than a year's worth of natural stress from tectonic movement. The government had disregarded warnings about so many large-scale dam projects in a seismically active area. Researchers have been denied access to seismological and geological data to examine the cause of the quake further.</td>\n",
       "      <td>Who disregarded warnings about dams in the area?</td>\n",
       "      <td>{'text': ['The government'], 'answer_start': [521]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5730a33f8ab72b1400f9c62a</td>\n",
       "      <td>Alfred_North_Whitehead</td>\n",
       "      <td>In higher organisms (like people), these two modes of perception combine into what Whitehead terms \"symbolic reference\", which links appearance with causation in a process that is so automatic that both people and animals have difficulty refraining from it. By way of illustration, Whitehead uses the example of a person's encounter with a chair. An ordinary person looks up, sees a colored shape, and immediately infers that it is a chair. However, an artist, Whitehead supposes, \"might not have jumped to the notion of a chair\", but instead \"might have stopped at the mere contemplation of a beautiful color and a beautiful shape.\" This is not the normal human reaction; most people place objects in categories by habit and instinct, without even thinking about it. Moreover, animals do the same thing. Using the same example, Whitehead points out that a dog \"would have acted immediately on the hypothesis of a chair and would have jumped onto it by way of using it as such.\" In this way symbolic reference is a fusion of pure sense perceptions on the one hand and causal relations on the other, and that it is in fact the causal relationships that dominate the more basic mentality (as the dog illustrates), while it is the sense perceptions which indicate a higher grade mentality (as the artist illustrates).</td>\n",
       "      <td>What dominates more basic mentality in symbolic reference?</td>\n",
       "      <td>{'text': ['causal relationships'], 'answer_start': [1126]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572a77f7fed8de19000d5c4f</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Several large companies are headquartered in or around Miami, including but not limited to: Akerman Senterfitt, Alienware, Arquitectonica, Arrow Air, Bacardi, Benihana, Brightstar Corporation, Burger King, Celebrity Cruises, Carnival Corporation, Carnival Cruise Lines, Crispin Porter + Bogusky, Duany Plater-Zyberk &amp; Company, Espírito Santo Financial Group, Fizber.com, Greenberg Traurig, Holland &amp; Knight, Inktel Direct, Interval International, Lennar, Navarro Discount Pharmacies, Norwegian Cruise Lines, Oceania Cruises, Perry Ellis International, RCTV International, Royal Caribbean Cruise Lines, Ryder Systems, Seabourn Cruise Line, Sedano's, Telefónica USA, UniMÁS, Telemundo, Univision, U.S. Century Bank, Vector Group and World Fuel Services. Because of its proximity to Latin America, Miami serves as the headquarters of Latin American operations for more than 1400 multinational corporations, including AIG, American Airlines, Cisco, Disney, Exxon, FedEx, Kraft Foods, LEO Pharma Americas, Microsoft, Yahoo, Oracle, SBC Communications, Sony, Symantec, Visa International, and Wal-Mart.</td>\n",
       "      <td>Approximately how many multinationals have their Latin American operation headquarters in Miami?</td>\n",
       "      <td>{'text': ['1400'], 'answer_start': [871]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572915f36aef051400154a50</td>\n",
       "      <td>Software_testing</td>\n",
       "      <td>There are many approaches available in software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas actually executing programmed code with a given set of test cases is referred to as dynamic testing. Static testing is often implicit, as proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules. Typical techniques for this are either using stubs/drivers or execution from a debugger environment.</td>\n",
       "      <td>When can dynamic testing occur?</td>\n",
       "      <td>{'text': ['before the program is 100% complete'], 'answer_start': [529]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572fe0d1947a6a140053cd9e</td>\n",
       "      <td>Printed_circuit_board</td>\n",
       "      <td>In boundary scan testing, test circuits integrated into various ICs on the board form temporary connections between the PCB traces to test that the ICs are mounted correctly. Boundary scan testing requires that all the ICs to be tested use a standard test configuration procedure, the most common one being the Joint Test Action Group (JTAG) standard. The JTAG test architecture provides a means to test interconnects between integrated circuits on a board without using physical test probes. JTAG tool vendors provide various types of stimulus and sophisticated algorithms, not only to detect the failing nets, but also to isolate the faults to specific nets, devices, and pins.</td>\n",
       "      <td>What would you avoid by using the Joint Test Action Group standard?</td>\n",
       "      <td>{'text': ['physical test probes'], 'answer_start': [471]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>573045e2947a6a140053d390</td>\n",
       "      <td>Swaziland</td>\n",
       "      <td>The considerable spending did not lead to more growth and did not benefit the poor. Much of the increased spending has gone to current expenditures related to wages, transfers, and subsidies. The wage bill today constitutes over 15% of GDP and 55% of total public spending; these are some of the highest levels on the African continent. The recent rapid growth in SACU revenues has, however, reversed the fiscal situation, and a sizeable surplus was recorded since 2006. SACU revenues today account for over 60% of total government revenues. On the positive side, the external debt burden has declined markedly over the last 20 years, and domestic debt is almost negligible; external debt as a percent of GDP was less than 20% in 2006.</td>\n",
       "      <td>What has happened to debt external onus  in Swaziland in the past two decades?</td>\n",
       "      <td>{'text': ['declined markedly'], 'answer_start': [593]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56d4d3b12ccc5a1400d83278</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In an interview published by Vogue in April 2013, Beyoncé was asked if she considers herself a feminist, to which she said, \"that word can be very extreme... But I guess I am a modern-day feminist. I do believe in equality\". She would later align herself more publicly with the movement, sampling \"We should all be feminists\", a speech delivered by Nigerian author Chimamanda Ngozi Adichie at a TEDxEuston conference in April 2013, in her song \"Flawless\", released later that year. She has also contributed to the Ban Bossy campaign, which uses television and social media to encourage leadership in girls.</td>\n",
       "      <td>Which campaign does Beyoncé contribute to that encourages leadership in females?</td>\n",
       "      <td>{'text': ['Ban Bossy'], 'answer_start': [514]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57263f2889a1e219009ac5be</td>\n",
       "      <td>Incandescent_light_bulb</td>\n",
       "      <td>In a conventional lamp, the evaporated tungsten eventually condenses on the inner surface of the glass envelope, darkening it. For bulbs that contain a vacuum, the darkening is uniform across the entire surface of the envelope. When a filling of inert gas is used, the evaporated tungsten is carried in the thermal convection currents of the gas, depositing preferentially on the uppermost part of the envelope and blackening just that portion of the envelope. An incandescent lamp that gives 93% or less of its initial light output at 75% of its rated life is regarded as unsatisfactory, when tested according to IEC Publication 60064. Light loss is due to filament evaporation and bulb blackening. Study of the problem of bulb blackening led to the discovery of the Edison effect, thermionic emission and invention of the vacuum tube.</td>\n",
       "      <td>What darkens a conventional bulb over its lifetime?</td>\n",
       "      <td>{'text': ['the evaporated tungsten eventually condenses on the inner surface of the glass envelope'], 'answer_start': [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570b26c7ec8fbc190045b888</td>\n",
       "      <td>Xbox_360</td>\n",
       "      <td>The Xbox 360's original graphical user interface was the Xbox 360 Dashboard; a tabbed interface that featured five \"Blades\" (formerly four blades), and was designed by AKQA and Audiobrain. It could be launched automatically when the console booted without a disc in it, or when the disc tray was ejected, but the user had the option to select what the console does if a game is in the tray on start up, or if inserted when already on. A simplified version of it was also accessible at any time via the Xbox Guide button on the gamepad. This simplified version showed the user's gamercard, Xbox Live messages and friends list. It also allowed for personal and music settings, in addition to voice or video chats, or returning to the Xbox Dashboard from the game.</td>\n",
       "      <td>The simple dashboard could be accessed by pressing what controller button?</td>\n",
       "      <td>{'text': ['the Xbox Guide button on the gamepad'], 'answer_start': [498]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5728929aff5b5019007da30c</td>\n",
       "      <td>Karl_Popper</td>\n",
       "      <td>In 1937, Popper finally managed to get a position that allowed him to emigrate to New Zealand, where he became lecturer in philosophy at Canterbury University College of the University of New Zealand in Christchurch. It was here that he wrote his influential work The Open Society and its Enemies. In Dunedin he met the Professor of Physiology John Carew Eccles and formed a lifelong friendship with him. In 1946, after the Second World War, he moved to the United Kingdom to become reader in logic and scientific method at the London School of Economics. Three years later, in 1949, he was appointed professor of logic and scientific method at the University of London. Popper was president of the Aristotelian Society from 1958 to 1959. He retired from academic life in 1969, though he remained intellectually active for the rest of his life. In 1985, he returned to Austria so that his wife could have her relatives around her during the last months of her life; she died in November that year. After the Ludwig Boltzmann Gesellschaft failed to establish him as the director of a newly founded branch researching the philosophy of science, he went back again to the United Kingdom in 1986, settling in Kenley, Surrey.</td>\n",
       "      <td>Which lifelong friend did Popper make in Dunedin?</td>\n",
       "      <td>{'text': ['John Carew Eccles'], 'answer_start': [344]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba21f98a-bf83-452d-a30b-f4dd1cf27fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:14:30.771939Z",
     "iopub.status.busy": "2024-01-23T02:14:30.771192Z",
     "iopub.status.idle": "2024-01-23T02:14:34.019007Z",
     "shell.execute_reply": "2024-01-23T02:14:34.018354Z",
     "shell.execute_reply.started": "2024-01-23T02:14:30.771909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/workspace/data/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81e8c1f-5d2d-44ee-9d01-096031e07e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:19:05.875066Z",
     "iopub.status.busy": "2024-01-23T02:19:05.874362Z",
     "iopub.status.idle": "2024-01-23T02:19:05.878842Z",
     "shell.execute_reply": "2024-01-23T02:19:05.878138Z",
     "shell.execute_reply.started": "2024-01-23T02:19:05.875025Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01e2833-ca44-4b96-a9f3-1001bfaa889b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:19:14.419027Z",
     "iopub.status.busy": "2024-01-23T02:19:14.418325Z",
     "iopub.status.idle": "2024-01-23T02:19:14.425096Z",
     "shell.execute_reply": "2024-01-23T02:19:14.424578Z",
     "shell.execute_reply.started": "2024-01-23T02:19:14.419002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b4d51e-53e9-4d66-a5a6-8778c85da307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:20:01.719800Z",
     "iopub.status.busy": "2024-01-23T02:20:01.719398Z",
     "iopub.status.idle": "2024-01-23T02:20:01.723282Z",
     "shell.execute_reply": "2024-01-23T02:20:01.722442Z",
     "shell.execute_reply.started": "2024-01-23T02:20:01.719778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The maximum length of a feature (question and context)\n",
    "max_length = 384 \n",
    "# The authorized overlap between two part of the context when splitting it is needed.\n",
    "doc_stride = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d0e04e-cf6b-481b-abbf-44dd606c86b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:20:12.357342Z",
     "iopub.status.busy": "2024-01-23T02:20:12.356927Z",
     "iopub.status.idle": "2024-01-23T02:20:12.556910Z",
     "shell.execute_reply": "2024-01-23T02:20:12.556185Z",
     "shell.execute_reply.started": "2024-01-23T02:20:12.357318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, example in enumerate(datasets[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = datasets[\"train\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b1e7aa-6dd0-4fd6-896a-5907d4280e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:20:21.481590Z",
     "iopub.status.busy": "2024-01-23T02:20:21.480954Z",
     "iopub.status.idle": "2024-01-23T02:20:21.487334Z",
     "shell.execute_reply": "2024-01-23T02:20:21.486741Z",
     "shell.execute_reply.started": "2024-01-23T02:20:21.481561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eabf8d0-0255-4f98-b54b-756be2471c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:20:29.140169Z",
     "iopub.status.busy": "2024-01-23T02:20:29.139763Z",
     "iopub.status.idle": "2024-01-23T02:20:29.146096Z",
     "shell.execute_reply": "2024-01-23T02:20:29.145499Z",
     "shell.execute_reply.started": "2024-01-23T02:20:29.140143Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"],\n",
    "              example[\"context\"],\n",
    "              max_length=max_length,\n",
    "              truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7042703-bba9-4226-8d57-b6497667e2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:20:55.099557Z",
     "iopub.status.busy": "2024-01-23T02:20:55.099135Z",
     "iopub.status.idle": "2024-01-23T02:20:55.104354Z",
     "shell.execute_reply": "2024-01-23T02:20:55.103746Z",
     "shell.execute_reply.started": "2024-01-23T02:20:55.099528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e427d39f-ed9f-4ee0-9f7d-015c4e53547a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:21:17.503339Z",
     "iopub.status.busy": "2024-01-23T02:21:17.502742Z",
     "iopub.status.idle": "2024-01-23T02:21:17.508029Z",
     "shell.execute_reply": "2024-01-23T02:21:17.507219Z",
     "shell.execute_reply.started": "2024-01-23T02:21:17.503311Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 157]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_example[\"input_ids\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc53a33-fc6b-42a4-ae54-16729aed0948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:22:05.827487Z",
     "iopub.status.busy": "2024-01-23T02:22:05.826786Z",
     "iopub.status.idle": "2024-01-23T02:22:05.835490Z",
     "shell.execute_reply": "2024-01-23T02:22:05.834603Z",
     "shell.execute_reply.started": "2024-01-23T02:22:05.827456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] how many wins does the notre dame men's basketball team have? [SEP] the men's basketball team has over 1, 600 wins, one of only 12 schools who have reached that mark, and have appeared in 28 ncaa tournaments. former player austin carr holds the record for most points scored in a single game of the tournament with 61. although the team has never won the ncaa tournament, they were named by the helms athletic foundation as national champions twice. the team has orchestrated a number of upsets of number one ranked teams, the most notable of which was ending ucla's record 88 - game winning streak in 1974. the team has beaten an additional eight number - one teams, and those nine wins rank second, to ucla's 10, all - time in wins against the top team. the team plays in newly renovated purcell pavilion ( within the edmund p. joyce center ), which reopened for the beginning of the 2009 – 2010 season. the team is coached by mike brey, who, as of the 2014 – 15 season, his fifteenth at notre dame, has achieved a 332 - 165 record. in 2009 they were invited to the nit, where they advanced to the semifinals but were beaten by penn state who went on and beat baylor in the championship. the 2010 – 11 team concluded its regular season ranked number seven in the country, with a record of 25 – 5, brey's fifth straight 20 - win season, and a second - place finish in the big east. during the 2014 - 15 season, the team went 32 - 6 and won the acc conference tournament, later advancing to the elite 8, where the fighting irish lost on a missed buzzer - beater against then undefeated kentucky. led by nba draft picks jerian grant and pat connaughton, the fighting irish beat the eventual national champion duke blue devils twice during the season. the 32 wins were [SEP]\n",
      "[CLS] how many wins does the notre dame men's basketball team have? [SEP] championship. the 2010 – 11 team concluded its regular season ranked number seven in the country, with a record of 25 – 5, brey's fifth straight 20 - win season, and a second - place finish in the big east. during the 2014 - 15 season, the team went 32 - 6 and won the acc conference tournament, later advancing to the elite 8, where the fighting irish lost on a missed buzzer - beater against then undefeated kentucky. led by nba draft picks jerian grant and pat connaughton, the fighting irish beat the eventual national champion duke blue devils twice during the season. the 32 wins were the most by the fighting irish team since 1908 - 09. [SEP]\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3208ba-5e34-41e7-9aaf-b2abf0ae6fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:22:42.392103Z",
     "iopub.status.busy": "2024-01-23T02:22:42.391692Z",
     "iopub.status.idle": "2024-01-23T02:22:42.397730Z",
     "shell.execute_reply": "2024-01-23T02:22:42.397176Z",
     "shell.execute_reply.started": "2024-01-23T02:22:42.392076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 3), (4, 8), (9, 13), (14, 18), (19, 22), (23, 28), (29, 33), (34, 37), (37, 38), (38, 39), (40, 50), (51, 55), (56, 60), (60, 61), (0, 0), (0, 3), (4, 7), (7, 8), (8, 9), (10, 20), (21, 25), (26, 29), (30, 34), (35, 36), (36, 37), (37, 40), (41, 45), (45, 46), (47, 50), (51, 53), (54, 58), (59, 61), (62, 69), (70, 73), (74, 78), (79, 86), (87, 91), (92, 96), (96, 97), (98, 101), (102, 106), (107, 115), (116, 118), (119, 121), (122, 126), (127, 138), (138, 139), (140, 146), (147, 153), (154, 160), (161, 165), (166, 171), (172, 175), (176, 182), (183, 186), (187, 191), (192, 198), (199, 205), (206, 208), (209, 210), (211, 217), (218, 222), (223, 225), (226, 229), (230, 240), (241, 245), (246, 248), (248, 249), (250, 258), (259, 262), (263, 267), (268, 271), (272, 277), (278, 281), (282, 285), (286, 290), (291, 301), (301, 302), (303, 307), (308, 312), (313, 318), (319, 321), (322, 325), (326, 330), (330, 331), (332, 340), (341, 351), (352, 354), (355, 363), (364, 373), (374, 379), (379, 380), (381, 384), (385, 389), (390, 393), (394, 406), (407, 408), (409, 415), (416, 418)]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06bef92a-acd1-4e8e-8490-008ed78275f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:23:40.653404Z",
     "iopub.status.busy": "2024-01-23T02:23:40.652957Z",
     "iopub.status.idle": "2024-01-23T02:23:40.657502Z",
     "shell.execute_reply": "2024-01-23T02:23:40.656946Z",
     "shell.execute_reply.started": "2024-01-23T02:23:40.653377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how How\n"
     ]
    }
   ],
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403d2cdc-7a99-46c0-8969-120d3136e7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:24:37.848171Z",
     "iopub.status.busy": "2024-01-23T02:24:37.847449Z",
     "iopub.status.idle": "2024-01-23T02:24:37.851458Z",
     "shell.execute_reply": "2024-01-23T02:24:37.850869Z",
     "shell.execute_reply.started": "2024-01-23T02:24:37.848146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16445f5c-d8e1-4016-ab6e-58b259e742b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:25:45.691212Z",
     "iopub.status.busy": "2024-01-23T02:25:45.690812Z",
     "iopub.status.idle": "2024-01-23T02:25:45.697539Z",
     "shell.execute_reply": "2024-01-23T02:25:45.696947Z",
     "shell.execute_reply.started": "2024-01-23T02:25:45.691188Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 26\n"
     ]
    }
   ],
   "source": [
    "answers = example[\"answers\"]\n",
    "start_char = answers[\"answer_start\"][0]\n",
    "end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "# 当前span在文本中的起始标记索引。\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "# 当前span在文本中的结束标记索引。\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "# 检测答案是否超出span范围（如果超出范围，该特征将以CLS标记索引标记）。\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # 将token_start_index和token_end_index移动到答案的两端。\n",
    "    # 注意：如果答案是最后一个单词，我们可以移到最后一个标记之后（边界情况）。\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"答案不在此特征中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0162a5c2-407b-47f5-8a47-dd4648cdaa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:25:57.050613Z",
     "iopub.status.busy": "2024-01-23T02:25:57.050176Z",
     "iopub.status.idle": "2024-01-23T02:25:57.054744Z",
     "shell.execute_reply": "2024-01-23T02:25:57.054049Z",
     "shell.execute_reply.started": "2024-01-23T02:25:57.050587Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 1, 600\n",
      "over 1,600\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "287740b0-a787-4dee-83cf-b0fffc494746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:26:08.659613Z",
     "iopub.status.busy": "2024-01-23T02:26:08.658923Z",
     "iopub.status.idle": "2024-01-23T02:26:08.662826Z",
     "shell.execute_reply": "2024-01-23T02:26:08.661956Z",
     "shell.execute_reply.started": "2024-01-23T02:26:08.659585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4638265e-d4f5-4b7c-9fb2-b70e31a25896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:28:10.277637Z",
     "iopub.status.busy": "2024-01-23T02:28:10.277121Z",
     "iopub.status.idle": "2024-01-23T02:28:10.286766Z",
     "shell.execute_reply": "2024-01-23T02:28:10.286139Z",
     "shell.execute_reply.started": "2024-01-23T02:28:10.277612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#整合\n",
    "def prepare_train_features(examples):\n",
    "    # 一些问题的左侧可能有很多空白字符，这对我们没有用，而且会导致上下文的截断失败\n",
    "    # （标记化的问题将占用大量空间）。因此，我们删除左侧的空白字符。\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和填充对我们的示例进行标记化，但保留溢出部分，使用步幅（stride）。\n",
    "    # 当上下文很长时，这会导致一个示例可能提供多个特征，其中每个特征的上下文都与前一个特征的上下文有一些重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例可能给我们提供多个特征（如果它具有很长的上下文），我们需要一个从特征到其对应示例的映射。这个键就提供了这个映射关系。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # 偏移映射将为我们提供从令牌到原始上下文中的字符位置的映射。这将帮助我们计算开始位置和结束位置。\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    # 让我们为这些示例进行标记！\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # 我们将使用CLS令牌的索引来标记不可能的答案。\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # 获取与该示例对应的序列（以了解上下文和问题是什么）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 一个示例可以提供多个跨度，这是包含此文本跨度的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # 如果没有给出答案，则将cls_index设置为答案。\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # 答案在文本中的开始和结束字符索引。\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # 当前跨度在文本中的开始令牌索引。\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # 当前跨度在文本中的结束令牌索引。\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 检测答案是否超出跨度（在这种情况下，该特征的标签将使用CLS索引）。\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # 否则，将token_start_index和token_end_index移到答案的两端。\n",
    "                # 注意：如果答案是最后一个单词（边缘情况），我们可以在最后一个偏移之后继续。\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "987b4d99-2520-4348-83a1-c8e02ef7b734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:30:06.594490Z",
     "iopub.status.busy": "2024-01-23T02:30:06.593766Z",
     "iopub.status.idle": "2024-01-23T02:30:43.784592Z",
     "shell.execute_reply": "2024-01-23T02:30:43.783806Z",
     "shell.execute_reply.started": "2024-01-23T02:30:06.594462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [00:33<00:00, 2649.07 examples/s]\n",
      "Map: 100%|██████████| 10570/10570 [00:04<00:00, 2584.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(prepare_train_features,\n",
    "                                  batched=True,\n",
    "                                  remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7729c85-2e29-4a4c-a9b5-df472462f138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:32:29.919428Z",
     "iopub.status.busy": "2024-01-23T02:32:29.918826Z",
     "iopub.status.idle": "2024-01-23T02:32:30.757277Z",
     "shell.execute_reply": "2024-01-23T02:32:30.756544Z",
     "shell.execute_reply.started": "2024-01-23T02:32:29.919400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at /mnt/workspace/data/distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5168d4c6-f3e4-47ed-946d-5eda638af7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:35:04.150913Z",
     "iopub.status.busy": "2024-01-23T02:35:04.150513Z",
     "iopub.status.idle": "2024-01-23T02:35:04.158967Z",
     "shell.execute_reply": "2024-01-23T02:35:04.158373Z",
     "shell.execute_reply.started": "2024-01-23T02:35:04.150888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "model_dir = \"models\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_dir}/{model_name}-finetuned-squad\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69675b3e-f5f4-4d13-a83e-b1bc3739459c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:35:11.793554Z",
     "iopub.status.busy": "2024-01-23T02:35:11.792831Z",
     "iopub.status.idle": "2024-01-23T02:35:11.796677Z",
     "shell.execute_reply": "2024-01-23T02:35:11.795841Z",
     "shell.execute_reply.started": "2024-01-23T02:35:11.793529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69081909-252f-48f3-abe4-cbc34c545bcd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T02:35:59.224789Z",
     "iopub.status.busy": "2024-01-23T02:35:59.224065Z",
     "iopub.status.idle": "2024-01-23T02:36:04.380010Z",
     "shell.execute_reply": "2024-01-23T02:36:04.379296Z",
     "shell.execute_reply.started": "2024-01-23T02:35:59.224756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6104eb2-a3bc-4c2b-9ae5-33824c514fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:35:42.506648Z",
     "iopub.status.busy": "2024-01-23T02:35:42.505956Z",
     "iopub.status.idle": "2024-01-23T02:35:42.510936Z",
     "shell.execute_reply": "2024-01-23T02:35:42.510203Z",
     "shell.execute_reply.started": "2024-01-23T02:35:42.506621Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 88524\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 10784\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b0870a-a15e-4dcb-85be-fe0d1f18f04c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T02:37:15.020391Z",
     "iopub.status.busy": "2024-01-23T02:37:15.019633Z",
     "iopub.status.idle": "2024-01-23T03:25:50.870900Z",
     "shell.execute_reply": "2024-01-23T03:25:50.870090Z",
     "shell.execute_reply.started": "2024-01-23T02:37:15.020347Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4152' max='4152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4152/4152 48:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.509400</td>\n",
       "      <td>1.269987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.125300</td>\n",
       "      <td>1.179514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4152, training_loss=1.3131521882808737, metrics={'train_runtime': 2915.5011, 'train_samples_per_second': 91.09, 'train_steps_per_second': 1.424, 'total_flos': 2.602335381127373e+16, 'train_loss': 1.3131521882808737, 'epoch': 3.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "173c18c2-634a-471c-bcf3-acfec9a69e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:37:12.064508Z",
     "iopub.status.busy": "2024-01-23T03:37:12.064082Z",
     "iopub.status.idle": "2024-01-23T03:37:12.067838Z",
     "shell.execute_reply": "2024-01-23T03:37:12.067182Z",
     "shell.execute_reply.started": "2024-01-23T03:37:12.064481Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model_path = f\"{model_dir}/{model_name}-finetuned-squad-trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7444ed4f-3078-4e3c-b92c-3ac88da8ea91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:37:15.435837Z",
     "iopub.status.busy": "2024-01-23T03:37:15.434960Z",
     "iopub.status.idle": "2024-01-23T03:37:16.009551Z",
     "shell.execute_reply": "2024-01-23T03:37:16.008896Z",
     "shell.execute_reply.started": "2024-01-23T03:37:15.435795Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_save = trainer.save_model(trained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba87d0-5aca-44e6-baea-1ef9350ba56e",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ecafcd5-cb14-42b7-a7f6-6b472ad3b54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:52:50.178742Z",
     "iopub.status.busy": "2024-01-23T03:52:50.178340Z",
     "iopub.status.idle": "2024-01-23T03:52:50.256401Z",
     "shell.execute_reply": "2024-01-23T03:52:50.255602Z",
     "shell.execute_reply.started": "2024-01-23T03:52:50.178718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = trainer.model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d956e59d-19ef-4f3f-a514-3a23f9c04f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:52:57.448587Z",
     "iopub.status.busy": "2024-01-23T03:52:57.447857Z",
     "iopub.status.idle": "2024-01-23T03:52:57.452824Z",
     "shell.execute_reply": "2024-01-23T03:52:57.452287Z",
     "shell.execute_reply.started": "2024-01-23T03:52:57.448558Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 384]), torch.Size([64, 384]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53a5b99a-051c-46df-8e92-16af0c906820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:53:08.225313Z",
     "iopub.status.busy": "2024-01-23T03:53:08.224717Z",
     "iopub.status.idle": "2024-01-23T03:53:08.232907Z",
     "shell.execute_reply": "2024-01-23T03:53:08.232412Z",
     "shell.execute_reply.started": "2024-01-23T03:53:08.225287Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 46,  57,  78,  43, 118, 107,  72,  35, 107,  34,  73,  41,  80,  91,\n",
       "         156,  35,  83,  91,  80,  58,  77,  31,  42,  53,  41,  35,  42,  77,\n",
       "          11,  44,  27, 133,  66,  40,  87,  44,  43,  83, 127,  26,  28,  33,\n",
       "          87, 127,  95,  25,  43, 132,  42,  29,  44,  46,  24,  44,  65,  58,\n",
       "          81,  14,  59,  72,  25,  36,  57,  43], device='cuda:0'),\n",
       " tensor([ 47,  58,  81,  44, 118, 110,  75,  37, 110,  36,  76,  42,  83,  94,\n",
       "         158,  35,  83,  94,  83,  60,  80,  31,  43,  54,  42,  35,  43,  80,\n",
       "          13,  45,  28, 133,  66,  41,  89,  45,  87,  85, 127,  27,  30,  34,\n",
       "          89, 127,  97,  26,  44, 132,  43,  30,  45,  47,  25,  45,  65,  59,\n",
       "          81,  14,  60,  72,  25,  36,  58,  43], device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fab770e8-4e8f-44cb-9f3f-da4987c4036e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:53:14.810476Z",
     "iopub.status.busy": "2024-01-23T03:53:14.809793Z",
     "iopub.status.idle": "2024-01-23T03:53:14.813229Z",
     "shell.execute_reply": "2024-01-23T03:53:14.812627Z",
     "shell.execute_reply.started": "2024-01-23T03:53:14.810449Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_best_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4815bb29-a8b7-449c-afab-3ce3de9df768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:53:24.187950Z",
     "iopub.status.busy": "2024-01-23T03:53:24.187230Z",
     "iopub.status.idle": "2024-01-23T03:53:24.194372Z",
     "shell.execute_reply": "2024-01-23T03:53:24.193794Z",
     "shell.execute_reply.started": "2024-01-23T03:53:24.187925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "\n",
    "# 获取最佳的起始和结束位置的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "valid_answers = []\n",
    "\n",
    "# 遍历起始位置和结束位置的索引组合\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index:  # 需要进一步测试以检查答案是否在上下文中\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\"  # 我们需要找到一种方法来获取与上下文中答案对应的原始子字符串\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd2aea34-e961-4c93-9fa5-dfe4f70248a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:53:48.980354Z",
     "iopub.status.busy": "2024-01-23T03:53:48.980027Z",
     "iopub.status.idle": "2024-01-23T03:53:48.986646Z",
     "shell.execute_reply": "2024-01-23T03:53:48.985868Z",
     "shell.execute_reply.started": "2024-01-23T03:53:48.980330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # 一些问题的左侧有很多空白，这些空白并不有用且会导致上下文截断失败（分词后的问题会占用很多空间）。\n",
    "    # 因此我们移除这些左侧空白\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和可能的填充对我们的示例进行分词，但使用步长保留溢出的令牌。这导致一个长上下文的示例可能产生\n",
    "    # 几个特征，每个特征的上下文都会稍微与前一个特征的上下文重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例在上下文很长时可能会产生几个特征，我们需要一个从特征映射到其对应示例的映射。这个键就是为了这个目的。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # 我们保留产生这个特征的示例ID，并且会存储偏移映射。\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # 获取与该示例对应的序列（以了解哪些是上下文，哪些是问题）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # 一个示例可以产生几个文本段，这里是包含该文本段的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # 将不属于上下文的偏移映射设置为None，以便容易确定一个令牌位置是否属于上下文。\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0799c748-35ff-4731-b0e9-efb13334a547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:54:09.903738Z",
     "iopub.status.busy": "2024-01-23T03:54:09.902989Z",
     "iopub.status.idle": "2024-01-23T03:54:14.766051Z",
     "shell.execute_reply": "2024-01-23T03:54:14.765461Z",
     "shell.execute_reply.started": "2024-01-23T03:54:09.903711Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10570/10570 [00:04<00:00, 2180.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3c565b3-ab29-4758-8dc9-9a5af6f4dc4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:54:22.879546Z",
     "iopub.status.busy": "2024-01-23T03:54:22.878931Z",
     "iopub.status.idle": "2024-01-23T03:55:03.622913Z",
     "shell.execute_reply": "2024-01-23T03:55:03.622297Z",
     "shell.execute_reply.started": "2024-01-23T03:54:22.879520Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d38c4df-e027-43a7-be68-c4717cda112f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:55:09.936932Z",
     "iopub.status.busy": "2024-01-23T03:55:09.936531Z",
     "iopub.status.idle": "2024-01-23T03:55:09.941063Z",
     "shell.execute_reply": "2024-01-23T03:55:09.940486Z",
     "shell.execute_reply.started": "2024-01-23T03:55:09.936907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c57dc6e-a206-4156-9765-657a1ace9438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:55:26.816684Z",
     "iopub.status.busy": "2024-01-23T03:55:26.815959Z",
     "iopub.status.idle": "2024-01-23T03:55:26.819565Z",
     "shell.execute_reply": "2024-01-23T03:55:26.818920Z",
     "shell.execute_reply.started": "2024-01-23T03:55:26.816659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_answer_length = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6269293-6264-4eaa-899c-0c8475199ded",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T03:56:19.607622Z",
     "iopub.status.busy": "2024-01-23T03:56:19.607208Z",
     "iopub.status.idle": "2024-01-23T03:56:19.619750Z",
     "shell.execute_reply": "2024-01-23T03:56:19.619221Z",
     "shell.execute_reply.started": "2024-01-23T03:56:19.607597Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 15.987539, 'text': 'Denver Broncos'},\n",
       " {'score': 13.9008255,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 11.577166, 'text': 'Broncos'},\n",
       " {'score': 11.349204, 'text': 'Carolina Panthers'},\n",
       " {'score': 10.372246, 'text': 'Denver'},\n",
       " {'score': 10.066029,\n",
       "  'text': 'American Football Conference (AFC) champion Denver Broncos'},\n",
       " {'score': 9.490452,\n",
       "  'text': 'Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 9.488808,\n",
       "  'text': 'The American Football Conference (AFC) champion Denver Broncos'},\n",
       " {'score': 8.565411,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference'},\n",
       " {'score': 7.9793143,\n",
       "  'text': 'American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 7.402093,\n",
       "  'text': 'The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 7.2129016,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina'},\n",
       " {'score': 6.880352,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC'},\n",
       " {'score': 6.4951615,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC)'},\n",
       " {'score': 6.4598207,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10'},\n",
       " {'score': 6.345136, 'text': 'Panthers'},\n",
       " {'score': 6.2361336,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title.'},\n",
       " {'score': 5.648181, 'text': 'champion Denver Broncos'},\n",
       " {'score': 5.4884853,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion'},\n",
       " {'score': 4.829633,\n",
       "  'text': 'National Football Conference (NFC) champion Carolina Panthers'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "\n",
    "# 第一个特征来自第一个示例。对于更一般的情况，我们需要将example_id匹配到一个示例索引\n",
    "context = datasets[\"test\"][0][\"context\"]\n",
    "\n",
    "# 收集最佳开始/结束逻辑的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # 我们需要细化这个测试，以检查答案是否在上下文中\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b655263-1f7b-441b-92cf-ec4533bd4665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:56:43.185974Z",
     "iopub.status.busy": "2024-01-23T03:56:43.185231Z",
     "iopub.status.idle": "2024-01-23T03:56:43.191378Z",
     "shell.execute_reply": "2024-01-23T03:56:43.190597Z",
     "shell.execute_reply.started": "2024-01-23T03:56:43.185950Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'answer_start': [177, 177, 177]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b911097d-55da-471b-bad8-229fd9344d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T03:57:23.748963Z",
     "iopub.status.busy": "2024-01-23T03:57:23.748215Z",
     "iopub.status.idle": "2024-01-23T03:57:34.423382Z",
     "shell.execute_reply": "2024-01-23T03:57:34.422727Z",
     "shell.execute_reply.started": "2024-01-23T03:57:23.748937Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"test\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2543e15b-624a-4a4f-828a-a661adb5e1ca",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T04:01:36.999432Z",
     "iopub.status.busy": "2024-01-23T04:01:36.998669Z",
     "iopub.status.idle": "2024-01-23T04:01:37.020154Z",
     "shell.execute_reply": "2024-01-23T04:01:37.019436Z",
     "shell.execute_reply.started": "2024-01-23T04:01:36.999405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from datasets import load_metric\n",
    "#metric = load_metric(\"/mnt/workspace/evaluate/metrics/squad\")\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"/mnt/workspace/evaluate/metrics/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5824c0ae-e296-4ac7-b395-1e98732a6e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T04:03:37.376754Z",
     "iopub.status.busy": "2024-01-23T04:03:37.376450Z",
     "iopub.status.idle": "2024-01-23T04:03:37.386936Z",
     "shell.execute_reply": "2024-01-23T04:03:37.386325Z",
     "shell.execute_reply.started": "2024-01-23T04:03:37.376729Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # 构建一个从示例到其对应特征的映射。\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # 我们需要填充的字典。\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # 日志记录。\n",
    "    print(f\"正在后处理 {len(examples)} 个示例的预测，这些预测分散在 {len(features)} 个特征中。\")\n",
    "\n",
    "    # 遍历所有示例！\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # 这些是与当前示例关联的特征的索引。\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # 仅在squad_v2为True时使用。\n",
    "        valid_answers = []\n",
    "        context = example[\"context\"]\n",
    "        # 遍历与当前示例关联的所有特征。\n",
    "        for feature_index in feature_indices:\n",
    "            # 我们获取模型对这个特征的预测。\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # 这将允许我们将logits中的某些位置映射到原始上下文中的文本跨度。\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # 更新最小空预测。\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # 浏览所有的最佳开始和结束logits，为 `n_best_size` 个最佳选择。\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # 在极少数情况下我们没有一个非空预测，我们创建一个假预测以避免失败。\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # 选择我们的最终答案：最佳答案或空答案（仅适用于squad_v2）\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae712a5f-c485-4839-b6ed-d4c1888a6318",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T04:04:37.907135Z",
     "iopub.status.busy": "2024-01-23T04:04:37.906422Z",
     "iopub.status.idle": "2024-01-23T04:05:14.670084Z",
     "shell.execute_reply": "2024-01-23T04:05:14.669206Z",
     "shell.execute_reply.started": "2024-01-23T04:04:37.907109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在后处理 10570 个示例的预测，这些预测分散在 10784 个特征中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:25<00:00, 408.29it/s]\n"
     ]
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"test\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fa266f8-7973-43e1-89b1-4c56a55d3b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T04:05:22.582655Z",
     "iopub.status.busy": "2024-01-23T04:05:22.582238Z",
     "iopub.status.idle": "2024-01-23T04:05:25.094542Z",
     "shell.execute_reply": "2024-01-23T04:05:25.093733Z",
     "shell.execute_reply.started": "2024-01-23T04:05:22.582630Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 74.38978240302744, 'f1': 83.42029040431296}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"test\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80bc55b-db5f-40ed-8434-eb54fa43aa94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "trans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
